{"ast":null,"code":"// Licensed to the Apache Software Foundation (ASF) under one\n// or more contributor license agreements.  See the NOTICE file\n// distributed with this work for additional information\n// regarding copyright ownership.  The ASF licenses this file\n// to you under the Apache License, Version 2.0 (the\n// \"License\"); you may not use this file except in compliance\n// with the License.  You may obtain a copy of the License at\n//\n//   http://www.apache.org/licenses/LICENSE-2.0\n//\n// Unless required by applicable law or agreed to in writing,\n// software distributed under the License is distributed on an\n// \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n// KIND, either express or implied.  See the License for the\n// specific language governing permissions and limitations\n// under the License.\nimport { Table } from '../table';\nimport { MAGIC } from './message';\nimport { Column } from '../column';\nimport { DataType } from '../type';\nimport { Field } from '../schema';\nimport { Message } from './metadata/message';\nimport * as metadata from './metadata/message';\nimport { FileBlock, Footer } from './metadata/file';\nimport { MessageHeader, MetadataVersion } from '../enum';\nimport { AsyncByteQueue } from '../io/stream';\nimport { VectorAssembler } from '../visitor/vectorassembler';\nimport { JSONTypeAssembler } from '../visitor/jsontypeassembler';\nimport { JSONVectorAssembler } from '../visitor/jsonvectorassembler';\nimport { toUint8Array } from '../util/buffer';\nimport { RecordBatch, _InternalEmptyPlaceholderRecordBatch } from '../recordbatch';\nimport { ReadableInterop } from '../io/interfaces';\nimport { isPromise, isAsyncIterable, isWritableDOMStream, isWritableNodeStream, isIterable, isObject } from '../util/compat';\nexport class RecordBatchWriter extends ReadableInterop {\n  constructor(options) {\n    super();\n    this._position = 0;\n    this._started = false; // @ts-ignore\n\n    this._sink = new AsyncByteQueue();\n    this._schema = null;\n    this._dictionaryBlocks = [];\n    this._recordBatchBlocks = [];\n    this._dictionaryDeltaOffsets = new Map();\n    isObject(options) || (options = {\n      autoDestroy: true,\n      writeLegacyIpcFormat: false\n    });\n    this._autoDestroy = typeof options.autoDestroy === 'boolean' ? options.autoDestroy : true;\n    this._writeLegacyIpcFormat = typeof options.writeLegacyIpcFormat === 'boolean' ? options.writeLegacyIpcFormat : false;\n  }\n  /** @nocollapse */\n  // @ts-ignore\n\n\n  static throughNode(options) {\n    throw new Error(`\"throughNode\" not available in this environment`);\n  }\n  /** @nocollapse */\n\n\n  static throughDOM( // @ts-ignore\n  writableStrategy, // @ts-ignore\n  readableStrategy) {\n    throw new Error(`\"throughDOM\" not available in this environment`);\n  }\n\n  toString() {\n    let sync = arguments.length > 0 && arguments[0] !== undefined ? arguments[0] : false;\n    return this._sink.toString(sync);\n  }\n\n  toUint8Array() {\n    let sync = arguments.length > 0 && arguments[0] !== undefined ? arguments[0] : false;\n    return this._sink.toUint8Array(sync);\n  }\n\n  writeAll(input) {\n    if (isPromise(input)) {\n      return input.then(x => this.writeAll(x));\n    } else if (isAsyncIterable(input)) {\n      return writeAllAsync(this, input);\n    }\n\n    return writeAll(this, input);\n  }\n\n  get closed() {\n    return this._sink.closed;\n  }\n\n  [Symbol.asyncIterator]() {\n    return this._sink[Symbol.asyncIterator]();\n  }\n\n  toDOMStream(options) {\n    return this._sink.toDOMStream(options);\n  }\n\n  toNodeStream(options) {\n    return this._sink.toNodeStream(options);\n  }\n\n  close() {\n    return this.reset()._sink.close();\n  }\n\n  abort(reason) {\n    return this.reset()._sink.abort(reason);\n  }\n\n  finish() {\n    this._autoDestroy ? this.close() : this.reset(this._sink, this._schema);\n    return this;\n  }\n\n  reset() {\n    let sink = arguments.length > 0 && arguments[0] !== undefined ? arguments[0] : this._sink;\n    let schema = arguments.length > 1 && arguments[1] !== undefined ? arguments[1] : null;\n\n    if (sink === this._sink || sink instanceof AsyncByteQueue) {\n      this._sink = sink;\n    } else {\n      this._sink = new AsyncByteQueue();\n\n      if (sink && isWritableDOMStream(sink)) {\n        this.toDOMStream({\n          type: 'bytes'\n        }).pipeTo(sink);\n      } else if (sink && isWritableNodeStream(sink)) {\n        this.toNodeStream({\n          objectMode: false\n        }).pipe(sink);\n      }\n    }\n\n    if (this._started && this._schema) {\n      this._writeFooter(this._schema);\n    }\n\n    this._started = false;\n    this._dictionaryBlocks = [];\n    this._recordBatchBlocks = [];\n    this._dictionaryDeltaOffsets = new Map();\n\n    if (!schema || !schema.compareTo(this._schema)) {\n      if (schema === null) {\n        this._position = 0;\n        this._schema = null;\n      } else {\n        this._started = true;\n        this._schema = schema;\n\n        this._writeSchema(schema);\n      }\n    }\n\n    return this;\n  }\n\n  write(payload) {\n    let schema = null;\n\n    if (!this._sink) {\n      throw new Error(`RecordBatchWriter is closed`);\n    } else if (payload === null || payload === undefined) {\n      return this.finish() && undefined;\n    } else if (payload instanceof Table && !(schema = payload.schema)) {\n      return this.finish() && undefined;\n    } else if (payload instanceof RecordBatch && !(schema = payload.schema)) {\n      return this.finish() && undefined;\n    }\n\n    if (schema && !schema.compareTo(this._schema)) {\n      if (this._started && this._autoDestroy) {\n        return this.close();\n      }\n\n      this.reset(this._sink, schema);\n    }\n\n    if (payload instanceof RecordBatch) {\n      if (!(payload instanceof _InternalEmptyPlaceholderRecordBatch)) {\n        this._writeRecordBatch(payload);\n      }\n    } else if (payload instanceof Table) {\n      this.writeAll(payload.chunks);\n    } else if (isIterable(payload)) {\n      this.writeAll(payload);\n    }\n  }\n\n  _writeMessage(message) {\n    let alignment = arguments.length > 1 && arguments[1] !== undefined ? arguments[1] : 8;\n    const a = alignment - 1;\n    const buffer = Message.encode(message);\n    const flatbufferSize = buffer.byteLength;\n    const prefixSize = !this._writeLegacyIpcFormat ? 8 : 4;\n    const alignedSize = flatbufferSize + prefixSize + a & ~a;\n    const nPaddingBytes = alignedSize - flatbufferSize - prefixSize;\n\n    if (message.headerType === MessageHeader.RecordBatch) {\n      this._recordBatchBlocks.push(new FileBlock(alignedSize, message.bodyLength, this._position));\n    } else if (message.headerType === MessageHeader.DictionaryBatch) {\n      this._dictionaryBlocks.push(new FileBlock(alignedSize, message.bodyLength, this._position));\n    } // If not in legacy pre-0.15.0 mode, write the stream continuation indicator\n\n\n    if (!this._writeLegacyIpcFormat) {\n      this._write(Int32Array.of(-1));\n    } // Write the flatbuffer size prefix including padding\n\n\n    this._write(Int32Array.of(alignedSize - prefixSize)); // Write the flatbuffer\n\n\n    if (flatbufferSize > 0) {\n      this._write(buffer);\n    } // Write any padding\n\n\n    return this._writePadding(nPaddingBytes);\n  }\n\n  _write(chunk) {\n    if (this._started) {\n      const buffer = toUint8Array(chunk);\n\n      if (buffer && buffer.byteLength > 0) {\n        this._sink.write(buffer);\n\n        this._position += buffer.byteLength;\n      }\n    }\n\n    return this;\n  }\n\n  _writeSchema(schema) {\n    return this._writeMessage(Message.from(schema));\n  } // @ts-ignore\n\n\n  _writeFooter(schema) {\n    // eos bytes\n    return this._writeLegacyIpcFormat ? this._write(Int32Array.of(0)) : this._write(Int32Array.of(-1, 0));\n  }\n\n  _writeMagic() {\n    return this._write(MAGIC);\n  }\n\n  _writePadding(nBytes) {\n    return nBytes > 0 ? this._write(new Uint8Array(nBytes)) : this;\n  }\n\n  _writeRecordBatch(batch) {\n    const {\n      byteLength,\n      nodes,\n      bufferRegions,\n      buffers\n    } = VectorAssembler.assemble(batch);\n    const recordBatch = new metadata.RecordBatch(batch.length, nodes, bufferRegions);\n    const message = Message.from(recordBatch, byteLength);\n    return this._writeDictionaries(batch)._writeMessage(message)._writeBodyBuffers(buffers);\n  }\n\n  _writeDictionaryBatch(dictionary, id) {\n    let isDelta = arguments.length > 2 && arguments[2] !== undefined ? arguments[2] : false;\n\n    this._dictionaryDeltaOffsets.set(id, dictionary.length + (this._dictionaryDeltaOffsets.get(id) || 0));\n\n    const {\n      byteLength,\n      nodes,\n      bufferRegions,\n      buffers\n    } = VectorAssembler.assemble(dictionary);\n    const recordBatch = new metadata.RecordBatch(dictionary.length, nodes, bufferRegions);\n    const dictionaryBatch = new metadata.DictionaryBatch(recordBatch, id, isDelta);\n    const message = Message.from(dictionaryBatch, byteLength);\n    return this._writeMessage(message)._writeBodyBuffers(buffers);\n  }\n\n  _writeBodyBuffers(buffers) {\n    let buffer;\n    let size, padding;\n\n    for (let i = -1, n = buffers.length; ++i < n;) {\n      if ((buffer = buffers[i]) && (size = buffer.byteLength) > 0) {\n        this._write(buffer);\n\n        if ((padding = (size + 7 & ~7) - size) > 0) {\n          this._writePadding(padding);\n        }\n      }\n    }\n\n    return this;\n  }\n\n  _writeDictionaries(batch) {\n    for (let [id, dictionary] of batch.dictionaries) {\n      let offset = this._dictionaryDeltaOffsets.get(id) || 0;\n\n      if (offset === 0 || (dictionary = dictionary.slice(offset)).length > 0) {\n        const chunks = 'chunks' in dictionary ? dictionary.chunks : [dictionary];\n\n        for (const chunk of chunks) {\n          this._writeDictionaryBatch(chunk, id, offset > 0);\n\n          offset += chunk.length;\n        }\n      }\n    }\n\n    return this;\n  }\n\n}\n/** @ignore */\n\nexport class RecordBatchStreamWriter extends RecordBatchWriter {\n  /** @nocollapse */\n  static writeAll(input, options) {\n    const writer = new RecordBatchStreamWriter(options);\n\n    if (isPromise(input)) {\n      return input.then(x => writer.writeAll(x));\n    } else if (isAsyncIterable(input)) {\n      return writeAllAsync(writer, input);\n    }\n\n    return writeAll(writer, input);\n  }\n\n}\n/** @ignore */\n\nexport class RecordBatchFileWriter extends RecordBatchWriter {\n  constructor() {\n    super();\n    this._autoDestroy = true;\n  }\n  /** @nocollapse */\n\n\n  static writeAll(input) {\n    const writer = new RecordBatchFileWriter();\n\n    if (isPromise(input)) {\n      return input.then(x => writer.writeAll(x));\n    } else if (isAsyncIterable(input)) {\n      return writeAllAsync(writer, input);\n    }\n\n    return writeAll(writer, input);\n  } // @ts-ignore\n\n\n  _writeSchema(schema) {\n    return this._writeMagic()._writePadding(2);\n  }\n\n  _writeFooter(schema) {\n    const buffer = Footer.encode(new Footer(schema, MetadataVersion.V4, this._recordBatchBlocks, this._dictionaryBlocks));\n    return super._writeFooter(schema) // EOS bytes for sequential readers\n    ._write(buffer) // Write the flatbuffer\n    ._write(Int32Array.of(buffer.byteLength)) // then the footer size suffix\n    ._writeMagic(); // then the magic suffix\n  }\n\n}\n/** @ignore */\n\nexport class RecordBatchJSONWriter extends RecordBatchWriter {\n  constructor() {\n    super();\n    this._autoDestroy = true;\n    this._recordBatches = [];\n    this._dictionaries = [];\n  }\n  /** @nocollapse */\n\n\n  static writeAll(input) {\n    return new RecordBatchJSONWriter().writeAll(input);\n  }\n\n  _writeMessage() {\n    return this;\n  } // @ts-ignore\n\n\n  _writeFooter(schema) {\n    return this;\n  }\n\n  _writeSchema(schema) {\n    return this._write(`{\\n  \"schema\": ${JSON.stringify({\n      fields: schema.fields.map(fieldToJSON)\n    }, null, 2)}`);\n  }\n\n  _writeDictionaries(batch) {\n    if (batch.dictionaries.size > 0) {\n      this._dictionaries.push(batch);\n    }\n\n    return this;\n  }\n\n  _writeDictionaryBatch(dictionary, id) {\n    let isDelta = arguments.length > 2 && arguments[2] !== undefined ? arguments[2] : false;\n\n    this._dictionaryDeltaOffsets.set(id, dictionary.length + (this._dictionaryDeltaOffsets.get(id) || 0));\n\n    this._write(this._dictionaryBlocks.length === 0 ? `    ` : `,\\n    `);\n\n    this._write(`${dictionaryBatchToJSON(dictionary, id, isDelta)}`);\n\n    this._dictionaryBlocks.push(new FileBlock(0, 0, 0));\n\n    return this;\n  }\n\n  _writeRecordBatch(batch) {\n    this._writeDictionaries(batch);\n\n    this._recordBatches.push(batch);\n\n    return this;\n  }\n\n  close() {\n    if (this._dictionaries.length > 0) {\n      this._write(`,\\n  \"dictionaries\": [\\n`);\n\n      for (const batch of this._dictionaries) {\n        super._writeDictionaries(batch);\n      }\n\n      this._write(`\\n  ]`);\n    }\n\n    if (this._recordBatches.length > 0) {\n      for (let i = -1, n = this._recordBatches.length; ++i < n;) {\n        this._write(i === 0 ? `,\\n  \"batches\": [\\n    ` : `,\\n    `);\n\n        this._write(`${recordBatchToJSON(this._recordBatches[i])}`);\n\n        this._recordBatchBlocks.push(new FileBlock(0, 0, 0));\n      }\n\n      this._write(`\\n  ]`);\n    }\n\n    if (this._schema) {\n      this._write(`\\n}`);\n    }\n\n    this._dictionaries = [];\n    this._recordBatches = [];\n    return super.close();\n  }\n\n}\n/** @ignore */\n\nfunction writeAll(writer, input) {\n  let chunks = input;\n\n  if (input instanceof Table) {\n    chunks = input.chunks;\n    writer.reset(undefined, input.schema);\n  }\n\n  for (const batch of chunks) {\n    writer.write(batch);\n  }\n\n  return writer.finish();\n}\n/** @ignore */\n\n\nasync function writeAllAsync(writer, batches) {\n  for await (const batch of batches) {\n    writer.write(batch);\n  }\n\n  return writer.finish();\n}\n/** @ignore */\n\n\nfunction fieldToJSON(_ref) {\n  let {\n    name,\n    type,\n    nullable\n  } = _ref;\n  const assembler = new JSONTypeAssembler();\n  return {\n    'name': name,\n    'nullable': nullable,\n    'type': assembler.visit(type),\n    'children': (type.children || []).map(fieldToJSON),\n    'dictionary': !DataType.isDictionary(type) ? undefined : {\n      'id': type.id,\n      'isOrdered': type.isOrdered,\n      'indexType': assembler.visit(type.indices)\n    }\n  };\n}\n/** @ignore */\n\n\nfunction dictionaryBatchToJSON(dictionary, id) {\n  let isDelta = arguments.length > 2 && arguments[2] !== undefined ? arguments[2] : false;\n  const field = new Field(`${id}`, dictionary.type, dictionary.nullCount > 0);\n  const columns = JSONVectorAssembler.assemble(new Column(field, [dictionary]));\n  return JSON.stringify({\n    'id': id,\n    'isDelta': isDelta,\n    'data': {\n      'count': dictionary.length,\n      'columns': columns\n    }\n  }, null, 2);\n}\n/** @ignore */\n\n\nfunction recordBatchToJSON(records) {\n  return JSON.stringify({\n    'count': records.length,\n    'columns': JSONVectorAssembler.assemble(records)\n  }, null, 2);\n}","map":{"version":3,"mappings":"AAAA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA,SAASA,KAAT,QAAsB,UAAtB;AACA,SAASC,KAAT,QAAsB,WAAtB;AAEA,SAASC,MAAT,QAAuB,WAAvB;AACA,SAASC,QAAT,QAAyB,SAAzB;AACA,SAAiBC,KAAjB,QAA8B,WAA9B;AACA,SAASC,OAAT,QAAwB,oBAAxB;AACA,OAAO,KAAKC,QAAZ,MAA0B,oBAA1B;AACA,SAASC,SAAT,EAAoBC,MAApB,QAAkC,iBAAlC;AACA,SAASC,aAAT,EAAwBC,eAAxB,QAA+C,SAA/C;AACA,SAAuBC,cAAvB,QAA6C,cAA7C;AACA,SAASC,eAAT,QAAgC,4BAAhC;AACA,SAASC,iBAAT,QAAkC,8BAAlC;AACA,SAASC,mBAAT,QAAoC,gCAApC;AACA,SAA+BC,YAA/B,QAAmD,gBAAnD;AACA,SAASC,WAAT,EAAsBC,oCAAtB,QAAkE,gBAAlE;AACA,SAAmBC,eAAnB,QAAoE,kBAApE;AACA,SAASC,SAAT,EAAoBC,eAApB,EAAqCC,mBAArC,EAA0DC,oBAA1D,EAAgFC,UAAhF,EAA4FC,QAA5F,QAA4G,gBAA5G;AAgBA,OAAM,MAAOC,iBAAP,SAA8EP,eAA9E,CAAyG;EAiB3GQ,YAAYC,OAAZ,EAAoD;IAChD;IAMM,iBAAY,CAAZ;IACA,gBAAW,KAAX,CAR0C,CAWpD;;IACU,aAAQ,IAAIhB,cAAJ,EAAR;IACA,eAAyB,IAAzB;IACA,yBAAiC,EAAjC;IACA,0BAAkC,EAAlC;IACA,+BAA0B,IAAIiB,GAAJ,EAA1B;IAdNJ,QAAQ,CAACG,OAAD,CAAR,KAAsBA,OAAO,GAAG;MAAEE,WAAW,EAAE,IAAf;MAAqBC,oBAAoB,EAAE;IAA3C,CAAhC;IACA,KAAKC,YAAL,GAAqB,OAAOJ,OAAO,CAACE,WAAf,KAA+B,SAAhC,GAA6CF,OAAO,CAACE,WAArD,GAAmE,IAAvF;IACA,KAAKG,qBAAL,GAA8B,OAAOL,OAAO,CAACG,oBAAf,KAAwC,SAAzC,GAAsDH,OAAO,CAACG,oBAA9D,GAAqF,KAAlH;EACH;EApBD;EACA;;;EACyB,OAAXG,WAAW,CAACN,OAAD,EAAoE;IACzF,MAAM,IAAIO,KAAJ,CAAU,iDAAV,CAAN;EACH;EACD;;;EACwB,OAAVC,UAAU,EACpB;EACAC,gBAFoB,EAGpB;EACAC,gBAJoB,EAIqC;IAEzD,MAAM,IAAIH,KAAJ,CAAU,gDAAV,CAAN;EACH;;EAsBMI,QAAQ,GAAkB;IAAA,IAAjBC,IAAiB,uEAAL,KAAK;IAC7B,OAAO,KAAKC,KAAL,CAAWF,QAAX,CAAoBC,IAApB,CAAP;EACH;;EAGMxB,YAAY,GAAkB;IAAA,IAAjBwB,IAAiB,uEAAL,KAAK;IACjC,OAAO,KAAKC,KAAL,CAAWzB,YAAX,CAAwBwB,IAAxB,CAAP;EACH;;EAMME,QAAQ,CAACC,KAAD,EAA8F;IACzG,IAAIvB,SAAS,CAAMuB,KAAN,CAAb,EAA2B;MACvB,OAAOA,KAAK,CAACC,IAAN,CAAYC,CAAD,IAAO,KAAKH,QAAL,CAAcG,CAAd,CAAlB,CAAP;IACH,CAFD,MAEO,IAAIxB,eAAe,CAAiBsB,KAAjB,CAAnB,EAA4C;MAC/C,OAAOG,aAAa,CAAC,IAAD,EAAOH,KAAP,CAApB;IACH;;IACD,OAAOD,QAAQ,CAAC,IAAD,EAAaC,KAAb,CAAf;EACH;;EAEgB,IAANI,MAAM;IAAK,OAAO,KAAKN,KAAL,CAAWM,MAAlB;EAA2B;;EACrB,CAApBC,MAAM,CAACC,aAAa,IAAC;IAAK,OAAO,KAAKR,KAAL,CAAWO,MAAM,CAACC,aAAlB,GAAP;EAA4C;;EACvEC,WAAW,CAACtB,OAAD,EAAmC;IAAI,OAAO,KAAKa,KAAL,CAAWS,WAAX,CAAuBtB,OAAvB,CAAP;EAAyC;;EAC3FuB,YAAY,CAACvB,OAAD,EAA2C;IAAI,OAAO,KAAKa,KAAL,CAAWU,YAAX,CAAwBvB,OAAxB,CAAP;EAA0C;;EAErGwB,KAAK;IACR,OAAO,KAAKC,KAAL,GAAaZ,KAAb,CAAmBW,KAAnB,EAAP;EACH;;EACME,KAAK,CAACC,MAAD,EAAa;IACrB,OAAO,KAAKF,KAAL,GAAaZ,KAAb,CAAmBa,KAAnB,CAAyBC,MAAzB,CAAP;EACH;;EACMC,MAAM;IACT,KAAKxB,YAAL,GAAoB,KAAKoB,KAAL,EAApB,GAAmC,KAAKC,KAAL,CAAW,KAAKZ,KAAhB,EAAuB,KAAKgB,OAA5B,CAAnC;IACA,OAAO,IAAP;EACH;;EACMJ,KAAK,GAAuF;IAAA,IAAtFK,IAAsF,uEAA3C,KAAKjB,KAAsC;IAAA,IAA/BkB,MAA+B,uEAAJ,IAAI;;IAE/F,IAAKD,IAAI,KAAK,KAAKjB,KAAf,IAA0BiB,IAAI,YAAY9C,cAA9C,EAA+D;MAC3D,KAAK6B,KAAL,GAAaiB,IAAb;IACH,CAFD,MAEO;MACH,KAAKjB,KAAL,GAAa,IAAI7B,cAAJ,EAAb;;MACA,IAAI8C,IAAI,IAAIpC,mBAAmB,CAACoC,IAAD,CAA/B,EAAuC;QACnC,KAAKR,WAAL,CAAiB;UAAEU,IAAI,EAAE;QAAR,CAAjB,EAAoCC,MAApC,CAA2CH,IAA3C;MACH,CAFD,MAEO,IAAIA,IAAI,IAAInC,oBAAoB,CAACmC,IAAD,CAAhC,EAAwC;QAC3C,KAAKP,YAAL,CAAkB;UAAEW,UAAU,EAAE;QAAd,CAAlB,EAAyCC,IAAzC,CAA8CL,IAA9C;MACH;IACJ;;IAED,IAAI,KAAKM,QAAL,IAAiB,KAAKP,OAA1B,EAAmC;MAC/B,KAAKQ,YAAL,CAAkB,KAAKR,OAAvB;IACH;;IAED,KAAKO,QAAL,GAAgB,KAAhB;IACA,KAAKE,iBAAL,GAAyB,EAAzB;IACA,KAAKC,kBAAL,GAA0B,EAA1B;IACA,KAAKC,uBAAL,GAA+B,IAAIvC,GAAJ,EAA/B;;IAEA,IAAI,CAAC8B,MAAD,IAAW,CAAEA,MAAM,CAACU,SAAP,CAAiB,KAAKZ,OAAtB,CAAjB,EAAkD;MAC9C,IAAIE,MAAM,KAAK,IAAf,EAAqB;QACjB,KAAKW,SAAL,GAAiB,CAAjB;QACA,KAAKb,OAAL,GAAe,IAAf;MACH,CAHD,MAGO;QACH,KAAKO,QAAL,GAAgB,IAAhB;QACA,KAAKP,OAAL,GAAeE,MAAf;;QACA,KAAKY,YAAL,CAAkBZ,MAAlB;MACH;IACJ;;IAED,OAAO,IAAP;EACH;;EAEMa,KAAK,CAACC,OAAD,EAAsE;IAE9E,IAAId,MAAM,GAAqB,IAA/B;;IAEA,IAAI,CAAC,KAAKlB,KAAV,EAAiB;MACb,MAAM,IAAIN,KAAJ,CAAU,6BAAV,CAAN;IACH,CAFD,MAEO,IAAIsC,OAAO,KAAK,IAAZ,IAAoBA,OAAO,KAAKC,SAApC,EAA+C;MAClD,OAAO,KAAKlB,MAAL,MAAiBkB,SAAxB;IACH,CAFM,MAEA,IAAID,OAAO,YAAYxE,KAAnB,IAA4B,EAAE0D,MAAM,GAAGc,OAAO,CAACd,MAAnB,CAAhC,EAA4D;MAC/D,OAAO,KAAKH,MAAL,MAAiBkB,SAAxB;IACH,CAFM,MAEA,IAAID,OAAO,YAAYxD,WAAnB,IAAkC,EAAE0C,MAAM,GAAGc,OAAO,CAACd,MAAnB,CAAtC,EAAkE;MACrE,OAAO,KAAKH,MAAL,MAAiBkB,SAAxB;IACH;;IAED,IAAIf,MAAM,IAAI,CAACA,MAAM,CAACU,SAAP,CAAiB,KAAKZ,OAAtB,CAAf,EAA+C;MAC3C,IAAI,KAAKO,QAAL,IAAiB,KAAKhC,YAA1B,EAAwC;QACpC,OAAO,KAAKoB,KAAL,EAAP;MACH;;MACD,KAAKC,KAAL,CAAW,KAAKZ,KAAhB,EAAuBkB,MAAvB;IACH;;IAED,IAAIc,OAAO,YAAYxD,WAAvB,EAAoC;MAChC,IAAI,EAAEwD,OAAO,YAAYvD,oCAArB,CAAJ,EAAgE;QAC5D,KAAKyD,iBAAL,CAAuBF,OAAvB;MACH;IACJ,CAJD,MAIO,IAAIA,OAAO,YAAYxE,KAAvB,EAA8B;MACjC,KAAKyC,QAAL,CAAc+B,OAAO,CAACG,MAAtB;IACH,CAFM,MAEA,IAAIpD,UAAU,CAACiD,OAAD,CAAd,EAAyB;MAC5B,KAAK/B,QAAL,CAAc+B,OAAd;IACH;EACJ;;EAESI,aAAa,CAA0BC,OAA1B,EAA4D;IAAA,IAAbC,SAAa,uEAAD,CAAC;IAE/E,MAAMC,CAAC,GAAGD,SAAS,GAAG,CAAtB;IACA,MAAME,MAAM,GAAG3E,OAAO,CAAC4E,MAAR,CAAeJ,OAAf,CAAf;IACA,MAAMK,cAAc,GAAGF,MAAM,CAACG,UAA9B;IACA,MAAMC,UAAU,GAAG,CAAC,KAAKpD,qBAAN,GAA8B,CAA9B,GAAkC,CAArD;IACA,MAAMqD,WAAW,GAAIH,cAAc,GAAGE,UAAjB,GAA8BL,CAA/B,GAAoC,CAACA,CAAzD;IACA,MAAMO,aAAa,GAAGD,WAAW,GAAGH,cAAd,GAA+BE,UAArD;;IAEA,IAAIP,OAAO,CAACU,UAAR,KAAuB9E,aAAa,CAACO,WAAzC,EAAsD;MAClD,KAAKkD,kBAAL,CAAwBsB,IAAxB,CAA6B,IAAIjF,SAAJ,CAAc8E,WAAd,EAA2BR,OAAO,CAACY,UAAnC,EAA+C,KAAKpB,SAApD,CAA7B;IACH,CAFD,MAEO,IAAIQ,OAAO,CAACU,UAAR,KAAuB9E,aAAa,CAACiF,eAAzC,EAA0D;MAC7D,KAAKzB,iBAAL,CAAuBuB,IAAvB,CAA4B,IAAIjF,SAAJ,CAAc8E,WAAd,EAA2BR,OAAO,CAACY,UAAnC,EAA+C,KAAKpB,SAApD,CAA5B;IACH,CAb8E,CAe/E;;;IACA,IAAI,CAAC,KAAKrC,qBAAV,EAAiC;MAC7B,KAAK2D,MAAL,CAAYC,UAAU,CAACC,EAAX,CAAc,CAAC,CAAf,CAAZ;IACH,CAlB8E,CAmB/E;;;IACA,KAAKF,MAAL,CAAYC,UAAU,CAACC,EAAX,CAAcR,WAAW,GAAGD,UAA5B,CAAZ,EApB+E,CAqB/E;;;IACA,IAAIF,cAAc,GAAG,CAArB,EAAwB;MAAE,KAAKS,MAAL,CAAYX,MAAZ;IAAsB,CAtB+B,CAuB/E;;;IACA,OAAO,KAAKc,aAAL,CAAmBR,aAAnB,CAAP;EACH;;EAESK,MAAM,CAACI,KAAD,EAA4B;IACxC,IAAI,KAAKhC,QAAT,EAAmB;MACf,MAAMiB,MAAM,GAAGjE,YAAY,CAACgF,KAAD,CAA3B;;MACA,IAAIf,MAAM,IAAIA,MAAM,CAACG,UAAP,GAAoB,CAAlC,EAAqC;QACjC,KAAK3C,KAAL,CAAW+B,KAAX,CAAiBS,MAAjB;;QACA,KAAKX,SAAL,IAAkBW,MAAM,CAACG,UAAzB;MACH;IACJ;;IACD,OAAO,IAAP;EACH;;EAESb,YAAY,CAACZ,MAAD,EAAkB;IACpC,OAAO,KAAKkB,aAAL,CAAmBvE,OAAO,CAAC2F,IAAR,CAAatC,MAAb,CAAnB,CAAP;EACH,CAtL0G,CAwL3G;;;EACUM,YAAY,CAACN,MAAD,EAAkB;IACpC;IACA,OAAO,KAAK1B,qBAAL,GACD,KAAK2D,MAAL,CAAYC,UAAU,CAACC,EAAX,CAAc,CAAd,CAAZ,CADC,GAED,KAAKF,MAAL,CAAYC,UAAU,CAACC,EAAX,CAAc,CAAC,CAAf,EAAkB,CAAlB,CAAZ,CAFN;EAGH;;EAESI,WAAW;IACjB,OAAO,KAAKN,MAAL,CAAY1F,KAAZ,CAAP;EACH;;EAES6F,aAAa,CAACI,MAAD,EAAe;IAClC,OAAOA,MAAM,GAAG,CAAT,GAAa,KAAKP,MAAL,CAAY,IAAIQ,UAAJ,CAAeD,MAAf,CAAZ,CAAb,GAAmD,IAA1D;EACH;;EAESxB,iBAAiB,CAAC0B,KAAD,EAAsB;IAC7C,MAAM;MAAEjB,UAAF;MAAckB,KAAd;MAAqBC,aAArB;MAAoCC;IAApC,IAAgD3F,eAAe,CAAC4F,QAAhB,CAAyBJ,KAAzB,CAAtD;IACA,MAAMK,WAAW,GAAG,IAAInG,QAAQ,CAACU,WAAb,CAAyBoF,KAAK,CAACM,MAA/B,EAAuCL,KAAvC,EAA8CC,aAA9C,CAApB;IACA,MAAMzB,OAAO,GAAGxE,OAAO,CAAC2F,IAAR,CAAaS,WAAb,EAA0BtB,UAA1B,CAAhB;IACA,OAAO,KACFwB,kBADE,CACiBP,KADjB,EAEFxB,aAFE,CAEYC,OAFZ,EAGF+B,iBAHE,CAGgBL,OAHhB,CAAP;EAIH;;EAESM,qBAAqB,CAACC,UAAD,EAAqBC,EAArB,EAAgD;IAAA,IAAfC,OAAe,uEAAL,KAAK;;IAC3E,KAAK7C,uBAAL,CAA6B8C,GAA7B,CAAiCF,EAAjC,EAAqCD,UAAU,CAACJ,MAAX,IAAqB,KAAKvC,uBAAL,CAA6B+C,GAA7B,CAAiCH,EAAjC,KAAwC,CAA7D,CAArC;;IACA,MAAM;MAAE5B,UAAF;MAAckB,KAAd;MAAqBC,aAArB;MAAoCC;IAApC,IAAgD3F,eAAe,CAAC4F,QAAhB,CAAyBM,UAAzB,CAAtD;IACA,MAAML,WAAW,GAAG,IAAInG,QAAQ,CAACU,WAAb,CAAyB8F,UAAU,CAACJ,MAApC,EAA4CL,KAA5C,EAAmDC,aAAnD,CAApB;IACA,MAAMa,eAAe,GAAG,IAAI7G,QAAQ,CAACoF,eAAb,CAA6Be,WAA7B,EAA0CM,EAA1C,EAA8CC,OAA9C,CAAxB;IACA,MAAMnC,OAAO,GAAGxE,OAAO,CAAC2F,IAAR,CAAamB,eAAb,EAA8BhC,UAA9B,CAAhB;IACA,OAAO,KACFP,aADE,CACYC,OADZ,EAEF+B,iBAFE,CAEgBL,OAFhB,CAAP;EAGH;;EAESK,iBAAiB,CAACL,OAAD,EAA2B;IAClD,IAAIvB,MAAJ;IACA,IAAIoC,IAAJ,EAAkBC,OAAlB;;IACA,KAAK,IAAIC,CAAC,GAAG,CAAC,CAAT,EAAYC,CAAC,GAAGhB,OAAO,CAACG,MAA7B,EAAqC,EAAEY,CAAF,GAAMC,CAA3C,GAA+C;MAC3C,IAAI,CAACvC,MAAM,GAAGuB,OAAO,CAACe,CAAD,CAAjB,KAAyB,CAACF,IAAI,GAAGpC,MAAM,CAACG,UAAf,IAA6B,CAA1D,EAA6D;QACzD,KAAKQ,MAAL,CAAYX,MAAZ;;QACA,IAAI,CAACqC,OAAO,GAAG,CAAED,IAAI,GAAG,CAAR,GAAa,CAAC,CAAf,IAAoBA,IAA/B,IAAuC,CAA3C,EAA8C;UAC1C,KAAKtB,aAAL,CAAmBuB,OAAnB;QACH;MACJ;IACJ;;IACD,OAAO,IAAP;EACH;;EAESV,kBAAkB,CAACP,KAAD,EAAsB;IAC9C,KAAK,IAAI,CAACW,EAAD,EAAKD,UAAL,CAAT,IAA6BV,KAAK,CAACoB,YAAnC,EAAiD;MAC7C,IAAIC,MAAM,GAAG,KAAKtD,uBAAL,CAA6B+C,GAA7B,CAAiCH,EAAjC,KAAwC,CAArD;;MACA,IAAIU,MAAM,KAAK,CAAX,IAAgB,CAACX,UAAU,GAAGA,UAAU,CAACY,KAAX,CAAiBD,MAAjB,CAAd,EAAwCf,MAAxC,GAAiD,CAArE,EAAwE;QACpE,MAAM/B,MAAM,GAAG,YAAYmC,UAAZ,GAA0BA,UAAkB,CAACnC,MAA7C,GAAsD,CAACmC,UAAD,CAArE;;QACA,KAAK,MAAMf,KAAX,IAAoBpB,MAApB,EAA4B;UACxB,KAAKkC,qBAAL,CAA2Bd,KAA3B,EAAkCgB,EAAlC,EAAsCU,MAAM,GAAG,CAA/C;;UACAA,MAAM,IAAI1B,KAAK,CAACW,MAAhB;QACH;MACJ;IACJ;;IACD,OAAO,IAAP;EACH;;AAvP0G;AA0P/G;;AACA,OAAM,MAAOiB,uBAAP,SAAoFlG,iBAApF,CAAwG;EAK1G;EACsB,OAARgB,QAAQ,CAA8CC,KAA9C,EAA0Df,OAA1D,EAAkG;IACpH,MAAMiG,MAAM,GAAG,IAAID,uBAAJ,CAA+BhG,OAA/B,CAAf;;IACA,IAAIR,SAAS,CAAMuB,KAAN,CAAb,EAA2B;MACvB,OAAOA,KAAK,CAACC,IAAN,CAAYC,CAAD,IAAOgF,MAAM,CAACnF,QAAP,CAAgBG,CAAhB,CAAlB,CAAP;IACH,CAFD,MAEO,IAAIxB,eAAe,CAAiBsB,KAAjB,CAAnB,EAA4C;MAC/C,OAAOG,aAAa,CAAC+E,MAAD,EAASlF,KAAT,CAApB;IACH;;IACD,OAAOD,QAAQ,CAACmF,MAAD,EAASlF,KAAT,CAAf;EACH;;AAdyG;AAiB9G;;AACA,OAAM,MAAOmF,qBAAP,SAAkFpG,iBAAlF,CAAsG;EAgBxGC;IACI;IACA,KAAKK,YAAL,GAAoB,IAApB;EACH;EAdD;;;EACsB,OAARU,QAAQ,CAA8CC,KAA9C,EAAwD;IAC1E,MAAMkF,MAAM,GAAG,IAAIC,qBAAJ,EAAf;;IACA,IAAI1G,SAAS,CAAMuB,KAAN,CAAb,EAA2B;MACvB,OAAOA,KAAK,CAACC,IAAN,CAAYC,CAAD,IAAOgF,MAAM,CAACnF,QAAP,CAAgBG,CAAhB,CAAlB,CAAP;IACH,CAFD,MAEO,IAAIxB,eAAe,CAAiBsB,KAAjB,CAAnB,EAA4C;MAC/C,OAAOG,aAAa,CAAC+E,MAAD,EAASlF,KAAT,CAApB;IACH;;IACD,OAAOD,QAAQ,CAACmF,MAAD,EAASlF,KAAT,CAAf;EACH,CAduG,CAqBxG;;;EACU4B,YAAY,CAACZ,MAAD,EAAkB;IACpC,OAAO,KAAKuC,WAAL,GAAmBH,aAAnB,CAAiC,CAAjC,CAAP;EACH;;EAES9B,YAAY,CAACN,MAAD,EAAkB;IACpC,MAAMsB,MAAM,GAAGxE,MAAM,CAACyE,MAAP,CAAc,IAAIzE,MAAJ,CACzBkD,MADyB,EACjBhD,eAAe,CAACoH,EADC,EAEzB,KAAK5D,kBAFoB,EAEA,KAAKD,iBAFL,CAAd,CAAf;IAIA,OAAO,MACFD,YADE,CACWN,MADX,EACmB;IADnB,CAEFiC,MAFE,CAEKX,MAFL,EAEa;IAFb,CAGFW,MAHE,CAGKC,UAAU,CAACC,EAAX,CAAcb,MAAM,CAACG,UAArB,CAHL,EAGuC;IAHvC,CAIFc,WAJE,EAAP,CALoC,CAShB;EACvB;;AApCuG;AAuC5G;;AACA,OAAM,MAAO8B,qBAAP,SAAkFtG,iBAAlF,CAAsG;EAexGC;IACI;IACA,KAAKK,YAAL,GAAoB,IAApB;IACA,KAAKiG,cAAL,GAAsB,EAAtB;IACA,KAAKC,aAAL,GAAqB,EAArB;EACH;EAbD;;;EACsB,OAARxF,QAAQ,CAA8EC,KAA9E,EAAwF;IAC1G,OAAO,IAAIqF,qBAAJ,GAA+BtF,QAA/B,CAAwCC,KAAxC,CAAP;EACH;;EAYSkC,aAAa;IAAK,OAAO,IAAP;EAAc,CAtB8D,CAuBxG;;;EACUZ,YAAY,CAACN,MAAD,EAAkB;IAAI,OAAO,IAAP;EAAc;;EAChDY,YAAY,CAACZ,MAAD,EAAkB;IACpC,OAAO,KAAKiC,MAAL,CAAY,kBACfuC,IAAI,CAACC,SAAL,CAAe;MAAEC,MAAM,EAAE1E,MAAM,CAAC0E,MAAP,CAAcC,GAAd,CAAkBC,WAAlB;IAAV,CAAf,EAA2D,IAA3D,EAAiE,CAAjE,CACJ,EAFO,CAAP;EAGH;;EACS3B,kBAAkB,CAACP,KAAD,EAAsB;IAC9C,IAAIA,KAAK,CAACoB,YAAN,CAAmBJ,IAAnB,GAA0B,CAA9B,EAAiC;MAC7B,KAAKa,aAAL,CAAmBzC,IAAnB,CAAwBY,KAAxB;IACH;;IACD,OAAO,IAAP;EACH;;EACSS,qBAAqB,CAACC,UAAD,EAAqBC,EAArB,EAAgD;IAAA,IAAfC,OAAe,uEAAL,KAAK;;IAC3E,KAAK7C,uBAAL,CAA6B8C,GAA7B,CAAiCF,EAAjC,EAAqCD,UAAU,CAACJ,MAAX,IAAqB,KAAKvC,uBAAL,CAA6B+C,GAA7B,CAAiCH,EAAjC,KAAwC,CAA7D,CAArC;;IACA,KAAKpB,MAAL,CAAY,KAAK1B,iBAAL,CAAuByC,MAAvB,KAAkC,CAAlC,GAAsC,MAAtC,GAA+C,SAA3D;;IACA,KAAKf,MAAL,CAAY,GAAG4C,qBAAqB,CAACzB,UAAD,EAAaC,EAAb,EAAiBC,OAAjB,CAAyB,EAA7D;;IACA,KAAK/C,iBAAL,CAAuBuB,IAAvB,CAA4B,IAAIjF,SAAJ,CAAc,CAAd,EAAiB,CAAjB,EAAoB,CAApB,CAA5B;;IACA,OAAO,IAAP;EACH;;EACSmE,iBAAiB,CAAC0B,KAAD,EAAsB;IAC7C,KAAKO,kBAAL,CAAwBP,KAAxB;;IACA,KAAK4B,cAAL,CAAoBxC,IAApB,CAAyBY,KAAzB;;IACA,OAAO,IAAP;EACH;;EACMjD,KAAK;IAER,IAAI,KAAK8E,aAAL,CAAmBvB,MAAnB,GAA4B,CAAhC,EAAmC;MAC/B,KAAKf,MAAL,CAAY,0BAAZ;;MACA,KAAK,MAAMS,KAAX,IAAoB,KAAK6B,aAAzB,EAAwC;QACpC,MAAMtB,kBAAN,CAAyBP,KAAzB;MACH;;MACD,KAAKT,MAAL,CAAY,OAAZ;IACH;;IAED,IAAI,KAAKqC,cAAL,CAAoBtB,MAApB,GAA6B,CAAjC,EAAoC;MAChC,KAAK,IAAIY,CAAC,GAAG,CAAC,CAAT,EAAYC,CAAC,GAAG,KAAKS,cAAL,CAAoBtB,MAAzC,EAAiD,EAAEY,CAAF,GAAMC,CAAvD,GAA2D;QACvD,KAAK5B,MAAL,CAAY2B,CAAC,KAAK,CAAN,GAAU,yBAAV,GAAsC,SAAlD;;QACA,KAAK3B,MAAL,CAAY,GAAG6C,iBAAiB,CAAC,KAAKR,cAAL,CAAoBV,CAApB,CAAD,CAAwB,EAAxD;;QACA,KAAKpD,kBAAL,CAAwBsB,IAAxB,CAA6B,IAAIjF,SAAJ,CAAc,CAAd,EAAiB,CAAjB,EAAoB,CAApB,CAA7B;MACH;;MACD,KAAKoF,MAAL,CAAY,OAAZ;IACH;;IAED,IAAI,KAAKnC,OAAT,EAAkB;MACd,KAAKmC,MAAL,CAAY,KAAZ;IACH;;IAED,KAAKsC,aAAL,GAAqB,EAArB;IACA,KAAKD,cAAL,GAAsB,EAAtB;IAEA,OAAO,MAAM7E,KAAN,EAAP;EACH;;AA3EuG;AA8E5G;;AACA,SAASV,QAAT,CAA+DmF,MAA/D,EAA6FlF,KAA7F,EAAuI;EACnI,IAAIiC,MAAM,GAAGjC,KAAb;;EACA,IAAIA,KAAK,YAAY1C,KAArB,EAA4B;IACxB2E,MAAM,GAAGjC,KAAK,CAACiC,MAAf;IACAiD,MAAM,CAACxE,KAAP,CAAaqB,SAAb,EAAwB/B,KAAK,CAACgB,MAA9B;EACH;;EACD,KAAK,MAAM0C,KAAX,IAAoBzB,MAApB,EAA4B;IACxBiD,MAAM,CAACrD,KAAP,CAAa6B,KAAb;EACH;;EACD,OAAOwB,MAAM,CAACrE,MAAP,EAAP;AACH;AAED;;;AACA,eAAeV,aAAf,CAA0E+E,MAA1E,EAAwGa,OAAxG,EAA8I;EAC1I,WAAW,MAAMrC,KAAjB,IAA0BqC,OAA1B,EAAmC;IAC/Bb,MAAM,CAACrD,KAAP,CAAa6B,KAAb;EACH;;EACD,OAAOwB,MAAM,CAACrE,MAAP,EAAP;AACH;AAED;;;AACA,SAAS+E,WAAT,OAAoD;EAAA,IAA/B;IAAEI,IAAF;IAAQ/E,IAAR;IAAcgF;EAAd,CAA+B;EAChD,MAAMC,SAAS,GAAG,IAAI/H,iBAAJ,EAAlB;EACA,OAAO;IACH,QAAQ6H,IADL;IACW,YAAYC,QADvB;IAEH,QAAQC,SAAS,CAACC,KAAV,CAAgBlF,IAAhB,CAFL;IAGH,YAAY,CAACA,IAAI,CAACmF,QAAL,IAAiB,EAAlB,EAAsBT,GAAtB,CAA0BC,WAA1B,CAHT;IAIH,cAAc,CAACnI,QAAQ,CAAC4I,YAAT,CAAsBpF,IAAtB,CAAD,GAA+Bc,SAA/B,GAA2C;MACrD,MAAMd,IAAI,CAACoD,EAD0C;MAErD,aAAapD,IAAI,CAACqF,SAFmC;MAGrD,aAAaJ,SAAS,CAACC,KAAV,CAAgBlF,IAAI,CAACsF,OAArB;IAHwC;EAJtD,CAAP;AAUH;AAED;;;AACA,SAASV,qBAAT,CAA+BzB,UAA/B,EAAmDC,EAAnD,EAA8E;EAAA,IAAfC,OAAe,uEAAL,KAAK;EAC1E,MAAMkC,KAAK,GAAG,IAAI9I,KAAJ,CAAU,GAAG2G,EAAE,EAAf,EAAmBD,UAAU,CAACnD,IAA9B,EAAoCmD,UAAU,CAACqC,SAAX,GAAuB,CAA3D,CAAd;EACA,MAAMC,OAAO,GAAGtI,mBAAmB,CAAC0F,QAApB,CAA6B,IAAItG,MAAJ,CAAWgJ,KAAX,EAAkB,CAACpC,UAAD,CAAlB,CAA7B,CAAhB;EACA,OAAOoB,IAAI,CAACC,SAAL,CAAe;IAClB,MAAMpB,EADY;IAElB,WAAWC,OAFO;IAGlB,QAAQ;MACJ,SAASF,UAAU,CAACJ,MADhB;MAEJ,WAAW0C;IAFP;EAHU,CAAf,EAOJ,IAPI,EAOE,CAPF,CAAP;AAQH;AAED;;;AACA,SAASZ,iBAAT,CAA2Ba,OAA3B,EAA+C;EAC3C,OAAOnB,IAAI,CAACC,SAAL,CAAe;IAClB,SAASkB,OAAO,CAAC3C,MADC;IAElB,WAAW5F,mBAAmB,CAAC0F,QAApB,CAA6B6C,OAA7B;EAFO,CAAf,EAGJ,IAHI,EAGE,CAHF,CAAP;AAIH","names":["Table","MAGIC","Column","DataType","Field","Message","metadata","FileBlock","Footer","MessageHeader","MetadataVersion","AsyncByteQueue","VectorAssembler","JSONTypeAssembler","JSONVectorAssembler","toUint8Array","RecordBatch","_InternalEmptyPlaceholderRecordBatch","ReadableInterop","isPromise","isAsyncIterable","isWritableDOMStream","isWritableNodeStream","isIterable","isObject","RecordBatchWriter","constructor","options","Map","autoDestroy","writeLegacyIpcFormat","_autoDestroy","_writeLegacyIpcFormat","throughNode","Error","throughDOM","writableStrategy","readableStrategy","toString","sync","_sink","writeAll","input","then","x","writeAllAsync","closed","Symbol","asyncIterator","toDOMStream","toNodeStream","close","reset","abort","reason","finish","_schema","sink","schema","type","pipeTo","objectMode","pipe","_started","_writeFooter","_dictionaryBlocks","_recordBatchBlocks","_dictionaryDeltaOffsets","compareTo","_position","_writeSchema","write","payload","undefined","_writeRecordBatch","chunks","_writeMessage","message","alignment","a","buffer","encode","flatbufferSize","byteLength","prefixSize","alignedSize","nPaddingBytes","headerType","push","bodyLength","DictionaryBatch","_write","Int32Array","of","_writePadding","chunk","from","_writeMagic","nBytes","Uint8Array","batch","nodes","bufferRegions","buffers","assemble","recordBatch","length","_writeDictionaries","_writeBodyBuffers","_writeDictionaryBatch","dictionary","id","isDelta","set","get","dictionaryBatch","size","padding","i","n","dictionaries","offset","slice","RecordBatchStreamWriter","writer","RecordBatchFileWriter","V4","RecordBatchJSONWriter","_recordBatches","_dictionaries","JSON","stringify","fields","map","fieldToJSON","dictionaryBatchToJSON","recordBatchToJSON","batches","name","nullable","assembler","visit","children","isDictionary","isOrdered","indices","field","nullCount","columns","records"],"sources":["ipc/writer.ts"],"sourcesContent":["// Licensed to the Apache Software Foundation (ASF) under one\n// or more contributor license agreements.  See the NOTICE file\n// distributed with this work for additional information\n// regarding copyright ownership.  The ASF licenses this file\n// to you under the Apache License, Version 2.0 (the\n// \"License\"); you may not use this file except in compliance\n// with the License.  You may obtain a copy of the License at\n//\n//   http://www.apache.org/licenses/LICENSE-2.0\n//\n// Unless required by applicable law or agreed to in writing,\n// software distributed under the License is distributed on an\n// \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n// KIND, either express or implied.  See the License for the\n// specific language governing permissions and limitations\n// under the License.\n\nimport { Table } from '../table';\nimport { MAGIC } from './message';\nimport { Vector } from '../vector';\nimport { Column } from '../column';\nimport { DataType } from '../type';\nimport { Schema, Field } from '../schema';\nimport { Message } from './metadata/message';\nimport * as metadata from './metadata/message';\nimport { FileBlock, Footer } from './metadata/file';\nimport { MessageHeader, MetadataVersion } from '../enum';\nimport { WritableSink, AsyncByteQueue } from '../io/stream';\nimport { VectorAssembler } from '../visitor/vectorassembler';\nimport { JSONTypeAssembler } from '../visitor/jsontypeassembler';\nimport { JSONVectorAssembler } from '../visitor/jsonvectorassembler';\nimport { ArrayBufferViewInput, toUint8Array } from '../util/buffer';\nimport { RecordBatch, _InternalEmptyPlaceholderRecordBatch } from '../recordbatch';\nimport { Writable, ReadableInterop, ReadableDOMStreamOptions } from '../io/interfaces';\nimport { isPromise, isAsyncIterable, isWritableDOMStream, isWritableNodeStream, isIterable, isObject } from '../util/compat';\n\nexport interface RecordBatchStreamWriterOptions {\n    /**\n     *\n     */\n    autoDestroy?: boolean;\n    /**\n     * A flag indicating whether the RecordBatchWriter should construct pre-0.15.0\n     * encapsulated IPC Messages, which reserves  4 bytes for the Message metadata\n     * length instead of 8.\n     * @see https://issues.apache.org/jira/browse/ARROW-6313\n     */\n    writeLegacyIpcFormat?: boolean;\n}\n\nexport class RecordBatchWriter<T extends { [key: string]: DataType } = any> extends ReadableInterop<Uint8Array> implements Writable<RecordBatch<T>> {\n\n    /** @nocollapse */\n    // @ts-ignore\n    public static throughNode(options?: import('stream').DuplexOptions & { autoDestroy: boolean }): import('stream').Duplex {\n        throw new Error(`\"throughNode\" not available in this environment`);\n    }\n    /** @nocollapse */\n    public static throughDOM<T extends { [key: string]: DataType }>(\n        // @ts-ignore\n        writableStrategy?: QueuingStrategy<RecordBatch<T>> & { autoDestroy: boolean },\n        // @ts-ignore\n        readableStrategy?: { highWaterMark?: number, size?: any }\n    ): { writable: WritableStream<Table<T> | RecordBatch<T>>, readable: ReadableStream<Uint8Array> } {\n        throw new Error(`\"throughDOM\" not available in this environment`);\n    }\n\n    constructor(options?: RecordBatchStreamWriterOptions) {\n        super();\n        isObject(options) || (options = { autoDestroy: true, writeLegacyIpcFormat: false });\n        this._autoDestroy = (typeof options.autoDestroy === 'boolean') ? options.autoDestroy : true;\n        this._writeLegacyIpcFormat = (typeof options.writeLegacyIpcFormat === 'boolean') ? options.writeLegacyIpcFormat : false;\n    }\n\n    protected _position = 0;\n    protected _started = false;\n    protected _autoDestroy: boolean;\n    protected _writeLegacyIpcFormat: boolean;\n    // @ts-ignore\n    protected _sink = new AsyncByteQueue();\n    protected _schema: Schema | null = null;\n    protected _dictionaryBlocks: FileBlock[] = [];\n    protected _recordBatchBlocks: FileBlock[] = [];\n    protected _dictionaryDeltaOffsets = new Map<number, number>();\n\n    public toString(sync: true): string;\n    public toString(sync?: false): Promise<string>;\n    public toString(sync: any = false) {\n        return this._sink.toString(sync) as Promise<string> | string;\n    }\n    public toUint8Array(sync: true): Uint8Array;\n    public toUint8Array(sync?: false): Promise<Uint8Array>;\n    public toUint8Array(sync: any = false) {\n        return this._sink.toUint8Array(sync) as Promise<Uint8Array> | Uint8Array;\n    }\n\n    public writeAll(input: Table<T> | Iterable<RecordBatch<T>>): this;\n    public writeAll(input: AsyncIterable<RecordBatch<T>>): Promise<this>;\n    public writeAll(input: PromiseLike<AsyncIterable<RecordBatch<T>>>): Promise<this>;\n    public writeAll(input: PromiseLike<Table<T> | Iterable<RecordBatch<T>>>): Promise<this>;\n    public writeAll(input: PromiseLike<any> | Table<T> | Iterable<RecordBatch<T>> | AsyncIterable<RecordBatch<T>>) {\n        if (isPromise<any>(input)) {\n            return input.then((x) => this.writeAll(x));\n        } else if (isAsyncIterable<RecordBatch<T>>(input)) {\n            return writeAllAsync(this, input);\n        }\n        return writeAll(this, <any> input);\n    }\n\n    public get closed() { return this._sink.closed; }\n    public [Symbol.asyncIterator]() { return this._sink[Symbol.asyncIterator](); }\n    public toDOMStream(options?: ReadableDOMStreamOptions) { return this._sink.toDOMStream(options); }\n    public toNodeStream(options?: import('stream').ReadableOptions) { return this._sink.toNodeStream(options); }\n\n    public close() {\n        return this.reset()._sink.close();\n    }\n    public abort(reason?: any) {\n        return this.reset()._sink.abort(reason);\n    }\n    public finish() {\n        this._autoDestroy ? this.close() : this.reset(this._sink, this._schema);\n        return this;\n    }\n    public reset(sink: WritableSink<ArrayBufferViewInput> = this._sink, schema: Schema<T> | null = null) {\n\n        if ((sink === this._sink) || (sink instanceof AsyncByteQueue)) {\n            this._sink = sink as AsyncByteQueue;\n        } else {\n            this._sink = new AsyncByteQueue();\n            if (sink && isWritableDOMStream(sink)) {\n                this.toDOMStream({ type: 'bytes' }).pipeTo(sink);\n            } else if (sink && isWritableNodeStream(sink)) {\n                this.toNodeStream({ objectMode: false }).pipe(sink);\n            }\n        }\n\n        if (this._started && this._schema) {\n            this._writeFooter(this._schema);\n        }\n\n        this._started = false;\n        this._dictionaryBlocks = [];\n        this._recordBatchBlocks = [];\n        this._dictionaryDeltaOffsets = new Map();\n\n        if (!schema || !(schema.compareTo(this._schema))) {\n            if (schema === null) {\n                this._position = 0;\n                this._schema = null;\n            } else {\n                this._started = true;\n                this._schema = schema;\n                this._writeSchema(schema);\n            }\n        }\n\n        return this;\n    }\n\n    public write(payload?: Table<T> | RecordBatch<T> | Iterable<RecordBatch<T>> | null) {\n\n        let schema: Schema<T> | null = null;\n\n        if (!this._sink) {\n            throw new Error(`RecordBatchWriter is closed`);\n        } else if (payload === null || payload === undefined) {\n            return this.finish() && undefined;\n        } else if (payload instanceof Table && !(schema = payload.schema)) {\n            return this.finish() && undefined;\n        } else if (payload instanceof RecordBatch && !(schema = payload.schema)) {\n            return this.finish() && undefined;\n        }\n\n        if (schema && !schema.compareTo(this._schema)) {\n            if (this._started && this._autoDestroy) {\n                return this.close();\n            }\n            this.reset(this._sink, schema);\n        }\n\n        if (payload instanceof RecordBatch) {\n            if (!(payload instanceof _InternalEmptyPlaceholderRecordBatch)) {\n                this._writeRecordBatch(payload);\n            }\n        } else if (payload instanceof Table) {\n            this.writeAll(payload.chunks);\n        } else if (isIterable(payload)) {\n            this.writeAll(payload);\n        }\n    }\n\n    protected _writeMessage<T extends MessageHeader>(message: Message<T>, alignment = 8) {\n\n        const a = alignment - 1;\n        const buffer = Message.encode(message);\n        const flatbufferSize = buffer.byteLength;\n        const prefixSize = !this._writeLegacyIpcFormat ? 8 : 4;\n        const alignedSize = (flatbufferSize + prefixSize + a) & ~a;\n        const nPaddingBytes = alignedSize - flatbufferSize - prefixSize;\n\n        if (message.headerType === MessageHeader.RecordBatch) {\n            this._recordBatchBlocks.push(new FileBlock(alignedSize, message.bodyLength, this._position));\n        } else if (message.headerType === MessageHeader.DictionaryBatch) {\n            this._dictionaryBlocks.push(new FileBlock(alignedSize, message.bodyLength, this._position));\n        }\n\n        // If not in legacy pre-0.15.0 mode, write the stream continuation indicator\n        if (!this._writeLegacyIpcFormat) {\n            this._write(Int32Array.of(-1));\n        }\n        // Write the flatbuffer size prefix including padding\n        this._write(Int32Array.of(alignedSize - prefixSize));\n        // Write the flatbuffer\n        if (flatbufferSize > 0) { this._write(buffer); }\n        // Write any padding\n        return this._writePadding(nPaddingBytes);\n    }\n\n    protected _write(chunk: ArrayBufferViewInput) {\n        if (this._started) {\n            const buffer = toUint8Array(chunk);\n            if (buffer && buffer.byteLength > 0) {\n                this._sink.write(buffer);\n                this._position += buffer.byteLength;\n            }\n        }\n        return this;\n    }\n\n    protected _writeSchema(schema: Schema<T>) {\n        return this._writeMessage(Message.from(schema));\n    }\n\n    // @ts-ignore\n    protected _writeFooter(schema: Schema<T>) {\n        // eos bytes\n        return this._writeLegacyIpcFormat\n            ? this._write(Int32Array.of(0))\n            : this._write(Int32Array.of(-1, 0));\n    }\n\n    protected _writeMagic() {\n        return this._write(MAGIC);\n    }\n\n    protected _writePadding(nBytes: number) {\n        return nBytes > 0 ? this._write(new Uint8Array(nBytes)) : this;\n    }\n\n    protected _writeRecordBatch(batch: RecordBatch<T>) {\n        const { byteLength, nodes, bufferRegions, buffers } = VectorAssembler.assemble(batch);\n        const recordBatch = new metadata.RecordBatch(batch.length, nodes, bufferRegions);\n        const message = Message.from(recordBatch, byteLength);\n        return this\n            ._writeDictionaries(batch)\n            ._writeMessage(message)\n            ._writeBodyBuffers(buffers);\n    }\n\n    protected _writeDictionaryBatch(dictionary: Vector, id: number, isDelta = false) {\n        this._dictionaryDeltaOffsets.set(id, dictionary.length + (this._dictionaryDeltaOffsets.get(id) || 0));\n        const { byteLength, nodes, bufferRegions, buffers } = VectorAssembler.assemble(dictionary);\n        const recordBatch = new metadata.RecordBatch(dictionary.length, nodes, bufferRegions);\n        const dictionaryBatch = new metadata.DictionaryBatch(recordBatch, id, isDelta);\n        const message = Message.from(dictionaryBatch, byteLength);\n        return this\n            ._writeMessage(message)\n            ._writeBodyBuffers(buffers);\n    }\n\n    protected _writeBodyBuffers(buffers: ArrayBufferView[]) {\n        let buffer: ArrayBufferView;\n        let size: number, padding: number;\n        for (let i = -1, n = buffers.length; ++i < n;) {\n            if ((buffer = buffers[i]) && (size = buffer.byteLength) > 0) {\n                this._write(buffer);\n                if ((padding = ((size + 7) & ~7) - size) > 0) {\n                    this._writePadding(padding);\n                }\n            }\n        }\n        return this;\n    }\n\n    protected _writeDictionaries(batch: RecordBatch<T>) {\n        for (let [id, dictionary] of batch.dictionaries) {\n            let offset = this._dictionaryDeltaOffsets.get(id) || 0;\n            if (offset === 0 || (dictionary = dictionary.slice(offset)).length > 0) {\n                const chunks = 'chunks' in dictionary ? (dictionary as any).chunks : [dictionary];\n                for (const chunk of chunks) {\n                    this._writeDictionaryBatch(chunk, id, offset > 0);\n                    offset += chunk.length;\n                }\n            }\n        }\n        return this;\n    }\n}\n\n/** @ignore */\nexport class RecordBatchStreamWriter<T extends { [key: string]: DataType } = any> extends RecordBatchWriter<T> {\n    public static writeAll<T extends { [key: string]: DataType } = any>(input: Table<T> | Iterable<RecordBatch<T>>, options?: RecordBatchStreamWriterOptions): RecordBatchStreamWriter<T>;\n    public static writeAll<T extends { [key: string]: DataType } = any>(input: AsyncIterable<RecordBatch<T>>, options?: RecordBatchStreamWriterOptions): Promise<RecordBatchStreamWriter<T>>;\n    public static writeAll<T extends { [key: string]: DataType } = any>(input: PromiseLike<AsyncIterable<RecordBatch<T>>>, options?: RecordBatchStreamWriterOptions): Promise<RecordBatchStreamWriter<T>>;\n    public static writeAll<T extends { [key: string]: DataType } = any>(input: PromiseLike<Table<T> | Iterable<RecordBatch<T>>>, options?: RecordBatchStreamWriterOptions): Promise<RecordBatchStreamWriter<T>>;\n    /** @nocollapse */\n    public static writeAll<T extends { [key: string]: DataType } = any>(input: any, options?: RecordBatchStreamWriterOptions) {\n        const writer = new RecordBatchStreamWriter<T>(options);\n        if (isPromise<any>(input)) {\n            return input.then((x) => writer.writeAll(x));\n        } else if (isAsyncIterable<RecordBatch<T>>(input)) {\n            return writeAllAsync(writer, input);\n        }\n        return writeAll(writer, input);\n    }\n}\n\n/** @ignore */\nexport class RecordBatchFileWriter<T extends { [key: string]: DataType } = any> extends RecordBatchWriter<T> {\n    public static writeAll<T extends { [key: string]: DataType } = any>(input: Table<T> | Iterable<RecordBatch<T>>): RecordBatchFileWriter<T>;\n    public static writeAll<T extends { [key: string]: DataType } = any>(input: AsyncIterable<RecordBatch<T>>): Promise<RecordBatchFileWriter<T>>;\n    public static writeAll<T extends { [key: string]: DataType } = any>(input: PromiseLike<AsyncIterable<RecordBatch<T>>>): Promise<RecordBatchFileWriter<T>>;\n    public static writeAll<T extends { [key: string]: DataType } = any>(input: PromiseLike<Table<T> | Iterable<RecordBatch<T>>>): Promise<RecordBatchFileWriter<T>>;\n    /** @nocollapse */\n    public static writeAll<T extends { [key: string]: DataType } = any>(input: any) {\n        const writer = new RecordBatchFileWriter<T>();\n        if (isPromise<any>(input)) {\n            return input.then((x) => writer.writeAll(x));\n        } else if (isAsyncIterable<RecordBatch<T>>(input)) {\n            return writeAllAsync(writer, input);\n        }\n        return writeAll(writer, input);\n    }\n\n    constructor() {\n        super();\n        this._autoDestroy = true;\n    }\n\n    // @ts-ignore\n    protected _writeSchema(schema: Schema<T>) {\n        return this._writeMagic()._writePadding(2);\n    }\n\n    protected _writeFooter(schema: Schema<T>) {\n        const buffer = Footer.encode(new Footer(\n            schema, MetadataVersion.V4,\n            this._recordBatchBlocks, this._dictionaryBlocks\n        ));\n        return super\n            ._writeFooter(schema) // EOS bytes for sequential readers\n            ._write(buffer) // Write the flatbuffer\n            ._write(Int32Array.of(buffer.byteLength)) // then the footer size suffix\n            ._writeMagic(); // then the magic suffix\n    }\n}\n\n/** @ignore */\nexport class RecordBatchJSONWriter<T extends { [key: string]: DataType } = any> extends RecordBatchWriter<T> {\n\n    public static writeAll<T extends { [key: string]: DataType } = any>(this: typeof RecordBatchWriter, input: Table<T> | Iterable<RecordBatch<T>>): RecordBatchJSONWriter<T>;\n    // @ts-ignore\n    public static writeAll<T extends { [key: string]: DataType } = any>(this: typeof RecordBatchWriter, input: AsyncIterable<RecordBatch<T>>): Promise<RecordBatchJSONWriter<T>>;\n    public static writeAll<T extends { [key: string]: DataType } = any>(this: typeof RecordBatchWriter, input: PromiseLike<AsyncIterable<RecordBatch<T>>>): Promise<RecordBatchJSONWriter<T>>;\n    public static writeAll<T extends { [key: string]: DataType } = any>(this: typeof RecordBatchWriter, input: PromiseLike<Table<T> | Iterable<RecordBatch<T>>>): Promise<RecordBatchJSONWriter<T>>;\n    /** @nocollapse */\n    public static writeAll<T extends { [key: string]: DataType } = any>(this: typeof RecordBatchWriter, input: any) {\n        return new RecordBatchJSONWriter<T>().writeAll(input as any);\n    }\n\n    private _recordBatches: RecordBatch[];\n    private _dictionaries: RecordBatch[];\n\n    constructor() {\n        super();\n        this._autoDestroy = true;\n        this._recordBatches = [];\n        this._dictionaries = [];\n    }\n\n    protected _writeMessage() { return this; }\n    // @ts-ignore\n    protected _writeFooter(schema: Schema<T>) { return this; }\n    protected _writeSchema(schema: Schema<T>) {\n        return this._write(`{\\n  \"schema\": ${\n            JSON.stringify({ fields: schema.fields.map(fieldToJSON) }, null, 2)\n        }`);\n    }\n    protected _writeDictionaries(batch: RecordBatch<T>) {\n        if (batch.dictionaries.size > 0) {\n            this._dictionaries.push(batch);\n        }\n        return this;\n    }\n    protected _writeDictionaryBatch(dictionary: Vector, id: number, isDelta = false) {\n        this._dictionaryDeltaOffsets.set(id, dictionary.length + (this._dictionaryDeltaOffsets.get(id) || 0));\n        this._write(this._dictionaryBlocks.length === 0 ? `    ` : `,\\n    `);\n        this._write(`${dictionaryBatchToJSON(dictionary, id, isDelta)}`);\n        this._dictionaryBlocks.push(new FileBlock(0, 0, 0));\n        return this;\n    }\n    protected _writeRecordBatch(batch: RecordBatch<T>) {\n        this._writeDictionaries(batch);\n        this._recordBatches.push(batch);\n        return this;\n    }\n    public close() {\n\n        if (this._dictionaries.length > 0) {\n            this._write(`,\\n  \"dictionaries\": [\\n`);\n            for (const batch of this._dictionaries) {\n                super._writeDictionaries(batch);\n            }\n            this._write(`\\n  ]`);\n        }\n\n        if (this._recordBatches.length > 0) {\n            for (let i = -1, n = this._recordBatches.length; ++i < n;) {\n                this._write(i === 0 ? `,\\n  \"batches\": [\\n    ` : `,\\n    `);\n                this._write(`${recordBatchToJSON(this._recordBatches[i])}`);\n                this._recordBatchBlocks.push(new FileBlock(0, 0, 0));\n            }\n            this._write(`\\n  ]`);\n        }\n\n        if (this._schema) {\n            this._write(`\\n}`);\n        }\n\n        this._dictionaries = [];\n        this._recordBatches = [];\n\n        return super.close();\n    }\n}\n\n/** @ignore */\nfunction writeAll<T extends { [key: string]: DataType } = any>(writer: RecordBatchWriter<T>, input: Table<T> | Iterable<RecordBatch<T>>) {\n    let chunks = input as Iterable<RecordBatch<T>>;\n    if (input instanceof Table) {\n        chunks = input.chunks;\n        writer.reset(undefined, input.schema);\n    }\n    for (const batch of chunks) {\n        writer.write(batch);\n    }\n    return writer.finish();\n}\n\n/** @ignore */\nasync function writeAllAsync<T extends { [key: string]: DataType } = any>(writer: RecordBatchWriter<T>, batches: AsyncIterable<RecordBatch<T>>) {\n    for await (const batch of batches) {\n        writer.write(batch);\n    }\n    return writer.finish();\n}\n\n/** @ignore */\nfunction fieldToJSON({ name, type, nullable }: Field): object {\n    const assembler = new JSONTypeAssembler();\n    return {\n        'name': name, 'nullable': nullable,\n        'type': assembler.visit(type),\n        'children': (type.children || []).map(fieldToJSON),\n        'dictionary': !DataType.isDictionary(type) ? undefined : {\n            'id': type.id,\n            'isOrdered': type.isOrdered,\n            'indexType': assembler.visit(type.indices)\n        }\n    };\n}\n\n/** @ignore */\nfunction dictionaryBatchToJSON(dictionary: Vector, id: number, isDelta = false) {\n    const field = new Field(`${id}`, dictionary.type, dictionary.nullCount > 0);\n    const columns = JSONVectorAssembler.assemble(new Column(field, [dictionary]));\n    return JSON.stringify({\n        'id': id,\n        'isDelta': isDelta,\n        'data': {\n            'count': dictionary.length,\n            'columns': columns\n        }\n    }, null, 2);\n}\n\n/** @ignore */\nfunction recordBatchToJSON(records: RecordBatch) {\n    return JSON.stringify({\n        'count': records.length,\n        'columns': JSONVectorAssembler.assemble(records)\n    }, null, 2);\n}\n"]},"metadata":{},"sourceType":"module"}