{"ast":null,"code":"import _toConsumableArray from \"/Users/nathan.schroeder/Documents/dev/template/streamlit_thoughtspot/frontend/node_modules/@babel/runtime/helpers/esm/toConsumableArray\";\n// Licensed to the Apache Software Foundation (ASF) under one\n// or more contributor license agreements.  See the NOTICE file\n// distributed with this work for additional information\n// regarding copyright ownership.  The ASF licenses this file\n// to you under the Apache License, Version 2.0 (the\n// \"License\"); you may not use this file except in compliance\n// with the License.  You may obtain a copy of the License at\n//\n//   http://www.apache.org/licenses/LICENSE-2.0\n//\n// Unless required by applicable law or agreed to in writing,\n// software distributed under the License is distributed on an\n// \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n// KIND, either express or implied.  See the License for the\n// specific language governing permissions and limitations\n// under the License.\nimport { Schema, Field } from '../../schema';\nimport { Dictionary, Utf8, Binary, Decimal, FixedSizeBinary, List, FixedSizeList, Map_, Struct, Union, Bool, Null, Int, Float, Date_, Time, Interval, Timestamp, Int32 } from '../../type';\nimport { DictionaryBatch, RecordBatch, FieldNode, BufferRegion } from './message';\nimport { TimeUnit, Precision, IntervalUnit, UnionMode, DateUnit } from '../../enum';\n/** @ignore */\n\nexport function schemaFromJSON(_schema) {\n  var dictionaries = arguments.length > 1 && arguments[1] !== undefined ? arguments[1] : new Map();\n  return new Schema(schemaFieldsFromJSON(_schema, dictionaries), customMetadataFromJSON(_schema['customMetadata']), dictionaries);\n}\n/** @ignore */\n\nexport function recordBatchFromJSON(b) {\n  return new RecordBatch(b['count'], fieldNodesFromJSON(b['columns']), buffersFromJSON(b['columns']));\n}\n/** @ignore */\n\nexport function dictionaryBatchFromJSON(b) {\n  return new DictionaryBatch(recordBatchFromJSON(b['data']), b['id'], b['isDelta']);\n}\n/** @ignore */\n\nfunction schemaFieldsFromJSON(_schema, dictionaries) {\n  return (_schema['fields'] || []).filter(Boolean).map(function (f) {\n    return Field.fromJSON(f, dictionaries);\n  });\n}\n/** @ignore */\n\n\nfunction fieldChildrenFromJSON(_field, dictionaries) {\n  return (_field['children'] || []).filter(Boolean).map(function (f) {\n    return Field.fromJSON(f, dictionaries);\n  });\n}\n/** @ignore */\n\n\nfunction fieldNodesFromJSON(xs) {\n  return (xs || []).reduce(function (fieldNodes, column) {\n    return [].concat(_toConsumableArray(fieldNodes), [new FieldNode(column['count'], nullCountFromJSON(column['VALIDITY']))], _toConsumableArray(fieldNodesFromJSON(column['children'])));\n  }, []);\n}\n/** @ignore */\n\n\nfunction buffersFromJSON(xs) {\n  var buffers = arguments.length > 1 && arguments[1] !== undefined ? arguments[1] : [];\n\n  for (var i = -1, n = (xs || []).length; ++i < n;) {\n    var column = xs[i];\n    column['VALIDITY'] && buffers.push(new BufferRegion(buffers.length, column['VALIDITY'].length));\n    column['TYPE'] && buffers.push(new BufferRegion(buffers.length, column['TYPE'].length));\n    column['OFFSET'] && buffers.push(new BufferRegion(buffers.length, column['OFFSET'].length));\n    column['DATA'] && buffers.push(new BufferRegion(buffers.length, column['DATA'].length));\n    buffers = buffersFromJSON(column['children'], buffers);\n  }\n\n  return buffers;\n}\n/** @ignore */\n\n\nfunction nullCountFromJSON(validity) {\n  return (validity || []).reduce(function (sum, val) {\n    return sum + +(val === 0);\n  }, 0);\n}\n/** @ignore */\n\n\nexport function fieldFromJSON(_field, dictionaries) {\n  var id;\n  var keys;\n  var field;\n  var dictMeta;\n  var type;\n  var dictType; // If no dictionary encoding\n\n  if (!dictionaries || !(dictMeta = _field['dictionary'])) {\n    type = typeFromJSON(_field, fieldChildrenFromJSON(_field, dictionaries));\n    field = new Field(_field['name'], type, _field['nullable'], customMetadataFromJSON(_field['customMetadata']));\n  } // tslint:disable\n  // If dictionary encoded and the first time we've seen this dictionary id, decode\n  // the data type and child fields, then wrap in a Dictionary type and insert the\n  // data type into the dictionary types map.\n  else if (!dictionaries.has(id = dictMeta['id'])) {\n    // a dictionary index defaults to signed 32 bit int if unspecified\n    keys = (keys = dictMeta['indexType']) ? indexTypeFromJSON(keys) : new Int32();\n    dictionaries.set(id, type = typeFromJSON(_field, fieldChildrenFromJSON(_field, dictionaries)));\n    dictType = new Dictionary(type, keys, id, dictMeta['isOrdered']);\n    field = new Field(_field['name'], dictType, _field['nullable'], customMetadataFromJSON(_field['customMetadata']));\n  } // If dictionary encoded, and have already seen this dictionary Id in the schema, then reuse the\n  // data type and wrap in a new Dictionary type and field.\n  else {\n    // a dictionary index defaults to signed 32 bit int if unspecified\n    keys = (keys = dictMeta['indexType']) ? indexTypeFromJSON(keys) : new Int32();\n    dictType = new Dictionary(dictionaries.get(id), keys, id, dictMeta['isOrdered']);\n    field = new Field(_field['name'], dictType, _field['nullable'], customMetadataFromJSON(_field['customMetadata']));\n  }\n\n  return field || null;\n}\n/** @ignore */\n\nfunction customMetadataFromJSON(_metadata) {\n  return new Map(Object.entries(_metadata || {}));\n}\n/** @ignore */\n\n\nfunction indexTypeFromJSON(_type) {\n  return new Int(_type['isSigned'], _type['bitWidth']);\n}\n/** @ignore */\n\n\nfunction typeFromJSON(f, children) {\n  var typeId = f['type']['name'];\n\n  switch (typeId) {\n    case 'NONE':\n      return new Null();\n\n    case 'null':\n      return new Null();\n\n    case 'binary':\n      return new Binary();\n\n    case 'utf8':\n      return new Utf8();\n\n    case 'bool':\n      return new Bool();\n\n    case 'list':\n      return new List((children || [])[0]);\n\n    case 'struct':\n      return new Struct(children || []);\n\n    case 'struct_':\n      return new Struct(children || []);\n  }\n\n  switch (typeId) {\n    case 'int':\n      {\n        var t = f['type'];\n        return new Int(t['isSigned'], t['bitWidth']);\n      }\n\n    case 'floatingpoint':\n      {\n        var _t = f['type'];\n        return new Float(Precision[_t['precision']]);\n      }\n\n    case 'decimal':\n      {\n        var _t2 = f['type'];\n        return new Decimal(_t2['scale'], _t2['precision']);\n      }\n\n    case 'date':\n      {\n        var _t3 = f['type'];\n        return new Date_(DateUnit[_t3['unit']]);\n      }\n\n    case 'time':\n      {\n        var _t4 = f['type'];\n        return new Time(TimeUnit[_t4['unit']], _t4['bitWidth']);\n      }\n\n    case 'timestamp':\n      {\n        var _t5 = f['type'];\n        return new Timestamp(TimeUnit[_t5['unit']], _t5['timezone']);\n      }\n\n    case 'interval':\n      {\n        var _t6 = f['type'];\n        return new Interval(IntervalUnit[_t6['unit']]);\n      }\n\n    case 'union':\n      {\n        var _t7 = f['type'];\n        return new Union(UnionMode[_t7['mode']], _t7['typeIds'] || [], children || []);\n      }\n\n    case 'fixedsizebinary':\n      {\n        var _t8 = f['type'];\n        return new FixedSizeBinary(_t8['byteWidth']);\n      }\n\n    case 'fixedsizelist':\n      {\n        var _t9 = f['type'];\n        return new FixedSizeList(_t9['listSize'], (children || [])[0]);\n      }\n\n    case 'map':\n      {\n        var _t10 = f['type'];\n        return new Map_((children || [])[0], _t10['keysSorted']);\n      }\n  }\n\n  throw new Error(\"Unrecognized type: \\\"\".concat(typeId, \"\\\"\"));\n}","map":{"version":3,"mappings":";AAAA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA,SAASA,MAAT,EAAiBC,KAAjB,QAA8B,cAA9B;AACA,SACcC,UADd,EAEIC,IAFJ,EAEUC,MAFV,EAEkBC,OAFlB,EAE2BC,eAF3B,EAGIC,IAHJ,EAGUC,aAHV,EAGyBC,IAHzB,EAG+BC,MAH/B,EAGuCC,KAHvC,EAIIC,IAJJ,EAIUC,IAJV,EAIgBC,GAJhB,EAIqBC,KAJrB,EAI4BC,KAJ5B,EAImCC,IAJnC,EAIyCC,QAJzC,EAImDC,SAJnD,EAI2EC,KAJ3E,QAKO,YALP;AAOA,SAASC,eAAT,EAA0BC,WAA1B,EAAuCC,SAAvC,EAAkDC,YAAlD,QAAsE,WAAtE;AACA,SAASC,QAAT,EAAmBC,SAAnB,EAA8BC,YAA9B,EAA4CC,SAA5C,EAAuDC,QAAvD,QAAuE,YAAvE;AAEA;;AACA,OAAM,SAAUC,cAAV,CAAyBC,OAAzB,EAAsF;EAAA,IAA/CC,YAA+C,uEAAT,IAAIC,GAAJ,EAAS;EACxF,OAAO,IAAIjC,MAAJ,CACHkC,oBAAoB,CAACH,OAAD,EAAUC,YAAV,CADjB,EAEHG,sBAAsB,CAACJ,OAAO,CAAC,gBAAD,CAAR,CAFnB,EAGHC,YAHG,CAAP;AAKH;AAED;;AACA,OAAM,SAAUI,mBAAV,CAA8BC,CAA9B,EAAoC;EACtC,OAAO,IAAIf,WAAJ,CACHe,CAAC,CAAC,OAAD,CADE,EAEHC,kBAAkB,CAACD,CAAC,CAAC,SAAD,CAAF,CAFf,EAGHE,eAAe,CAACF,CAAC,CAAC,SAAD,CAAF,CAHZ,CAAP;AAKH;AAED;;AACA,OAAM,SAAUG,uBAAV,CAAkCH,CAAlC,EAAwC;EAC1C,OAAO,IAAIhB,eAAJ,CACHe,mBAAmB,CAACC,CAAC,CAAC,MAAD,CAAF,CADhB,EAEHA,CAAC,CAAC,IAAD,CAFE,EAEMA,CAAC,CAAC,SAAD,CAFP,CAAP;AAIH;AAED;;AACA,SAASH,oBAAT,CAA8BH,OAA9B,EAA4CC,YAA5C,EAAgF;EAC5E,OAAO,CAACD,OAAO,CAAC,QAAD,CAAP,IAAqB,EAAtB,EAA0BU,MAA1B,CAAiCC,OAAjC,EAA0CC,GAA1C,CAA8C,UAACC,CAAD;IAAA,OAAY3C,KAAK,CAAC4C,QAAN,CAAeD,CAAf,EAAkBZ,YAAlB,CAAZ;EAAA,CAA9C,CAAP;AACH;AAED;;;AACA,SAASc,qBAAT,CAA+BC,MAA/B,EAA4Cf,YAA5C,EAAgF;EAC5E,OAAO,CAACe,MAAM,CAAC,UAAD,CAAN,IAAsB,EAAvB,EAA2BN,MAA3B,CAAkCC,OAAlC,EAA2CC,GAA3C,CAA+C,UAACC,CAAD;IAAA,OAAY3C,KAAK,CAAC4C,QAAN,CAAeD,CAAf,EAAkBZ,YAAlB,CAAZ;EAAA,CAA/C,CAAP;AACH;AAED;;;AACA,SAASM,kBAAT,CAA4BU,EAA5B,EAAqC;EACjC,OAAO,CAACA,EAAE,IAAI,EAAP,EAAWC,MAAX,CAA+B,UAACC,UAAD,EAAaC,MAAb;IAAA,oCAC/BD,UAD+B,IAElC,IAAI3B,SAAJ,CACI4B,MAAM,CAAC,OAAD,CADV,EAEIC,iBAAiB,CAACD,MAAM,CAAC,UAAD,CAAP,CAFrB,CAFkC,sBAM/Bb,kBAAkB,CAACa,MAAM,CAAC,UAAD,CAAP,CANa;EAAA,CAA/B,EAOJ,EAPI,CAAP;AAQH;AAED;;;AACA,SAASZ,eAAT,CAAyBS,EAAzB,EAAgE;EAAA,IAA5BK,OAA4B,uEAAF,EAAE;;EAC5D,KAAK,IAAIC,CAAC,GAAG,CAAC,CAAT,EAAYC,CAAC,GAAG,CAACP,EAAE,IAAI,EAAP,EAAWQ,MAAhC,EAAwC,EAAEF,CAAF,GAAMC,CAA9C,GAAkD;IAC9C,IAAMJ,MAAM,GAAGH,EAAE,CAACM,CAAD,CAAjB;IACAH,MAAM,CAAC,UAAD,CAAN,IAAsBE,OAAO,CAACI,IAAR,CAAa,IAAIjC,YAAJ,CAAiB6B,OAAO,CAACG,MAAzB,EAAiCL,MAAM,CAAC,UAAD,CAAN,CAAmBK,MAApD,CAAb,CAAtB;IACAL,MAAM,CAAC,MAAD,CAAN,IAAkBE,OAAO,CAACI,IAAR,CAAa,IAAIjC,YAAJ,CAAiB6B,OAAO,CAACG,MAAzB,EAAiCL,MAAM,CAAC,MAAD,CAAN,CAAeK,MAAhD,CAAb,CAAlB;IACAL,MAAM,CAAC,QAAD,CAAN,IAAoBE,OAAO,CAACI,IAAR,CAAa,IAAIjC,YAAJ,CAAiB6B,OAAO,CAACG,MAAzB,EAAiCL,MAAM,CAAC,QAAD,CAAN,CAAiBK,MAAlD,CAAb,CAApB;IACAL,MAAM,CAAC,MAAD,CAAN,IAAkBE,OAAO,CAACI,IAAR,CAAa,IAAIjC,YAAJ,CAAiB6B,OAAO,CAACG,MAAzB,EAAiCL,MAAM,CAAC,MAAD,CAAN,CAAeK,MAAhD,CAAb,CAAlB;IACAH,OAAO,GAAGd,eAAe,CAACY,MAAM,CAAC,UAAD,CAAP,EAAqBE,OAArB,CAAzB;EACH;;EACD,OAAOA,OAAP;AACH;AAED;;;AACA,SAASD,iBAAT,CAA2BM,QAA3B,EAA6C;EACzC,OAAO,CAACA,QAAQ,IAAI,EAAb,EAAiBT,MAAjB,CAAwB,UAACU,GAAD,EAAMC,GAAN;IAAA,OAAcD,GAAG,GAAG,EAAEC,GAAG,KAAK,CAAV,CAApB;EAAA,CAAxB,EAA0D,CAA1D,CAAP;AACH;AAED;;;AACA,OAAM,SAAUC,aAAV,CAAwBd,MAAxB,EAAqCf,YAArC,EAAyE;EAE3E,IAAI8B,EAAJ;EACA,IAAIC,IAAJ;EACA,IAAIC,KAAJ;EACA,IAAIC,QAAJ;EACA,IAAIC,IAAJ;EACA,IAAIC,QAAJ,CAP2E,CAS3E;;EACA,IAAI,CAACnC,YAAD,IAAiB,EAAEiC,QAAQ,GAAGlB,MAAM,CAAC,YAAD,CAAnB,CAArB,EAAyD;IACrDmB,IAAI,GAAGE,YAAY,CAACrB,MAAD,EAASD,qBAAqB,CAACC,MAAD,EAASf,YAAT,CAA9B,CAAnB;IACAgC,KAAK,GAAG,IAAI/D,KAAJ,CAAU8C,MAAM,CAAC,MAAD,CAAhB,EAA0BmB,IAA1B,EAAgCnB,MAAM,CAAC,UAAD,CAAtC,EAAoDZ,sBAAsB,CAACY,MAAM,CAAC,gBAAD,CAAP,CAA1E,CAAR;EACH,CAHD,CAIA;EACA;EACA;EACA;EAPA,KAQK,IAAI,CAACf,YAAY,CAACqC,GAAb,CAAiBP,EAAE,GAAGG,QAAQ,CAAC,IAAD,CAA9B,CAAL,EAA4C;IAC7C;IACAF,IAAI,GAAG,CAACA,IAAI,GAAGE,QAAQ,CAAC,WAAD,CAAhB,IAAiCK,iBAAiB,CAACP,IAAD,CAAlD,GAAoE,IAAI3C,KAAJ,EAA3E;IACAY,YAAY,CAACuC,GAAb,CAAiBT,EAAjB,EAAqBI,IAAI,GAAGE,YAAY,CAACrB,MAAD,EAASD,qBAAqB,CAACC,MAAD,EAASf,YAAT,CAA9B,CAAxC;IACAmC,QAAQ,GAAG,IAAIjE,UAAJ,CAAegE,IAAf,EAAqBH,IAArB,EAA2BD,EAA3B,EAA+BG,QAAQ,CAAC,WAAD,CAAvC,CAAX;IACAD,KAAK,GAAG,IAAI/D,KAAJ,CAAU8C,MAAM,CAAC,MAAD,CAAhB,EAA0BoB,QAA1B,EAAoCpB,MAAM,CAAC,UAAD,CAA1C,EAAwDZ,sBAAsB,CAACY,MAAM,CAAC,gBAAD,CAAP,CAA9E,CAAR;EACH,CANI,CAOL;EACA;EARK,KASA;IACD;IACAgB,IAAI,GAAG,CAACA,IAAI,GAAGE,QAAQ,CAAC,WAAD,CAAhB,IAAiCK,iBAAiB,CAACP,IAAD,CAAlD,GAAoE,IAAI3C,KAAJ,EAA3E;IACA+C,QAAQ,GAAG,IAAIjE,UAAJ,CAAe8B,YAAY,CAACwC,GAAb,CAAiBV,EAAjB,CAAf,EAAsCC,IAAtC,EAA4CD,EAA5C,EAAgDG,QAAQ,CAAC,WAAD,CAAxD,CAAX;IACAD,KAAK,GAAG,IAAI/D,KAAJ,CAAU8C,MAAM,CAAC,MAAD,CAAhB,EAA0BoB,QAA1B,EAAoCpB,MAAM,CAAC,UAAD,CAA1C,EAAwDZ,sBAAsB,CAACY,MAAM,CAAC,gBAAD,CAAP,CAA9E,CAAR;EACH;;EACD,OAAOiB,KAAK,IAAI,IAAhB;AACH;AAED;;AACA,SAAS7B,sBAAT,CAAgCsC,SAAhC,EAAkD;EAC9C,OAAO,IAAIxC,GAAJ,CAAwByC,MAAM,CAACC,OAAP,CAAeF,SAAS,IAAI,EAA5B,CAAxB,CAAP;AACH;AAED;;;AACA,SAASH,iBAAT,CAA2BM,KAA3B,EAAqC;EACjC,OAAO,IAAI9D,GAAJ,CAAQ8D,KAAK,CAAC,UAAD,CAAb,EAA2BA,KAAK,CAAC,UAAD,CAAhC,CAAP;AACH;AAED;;;AACA,SAASR,YAAT,CAAsBxB,CAAtB,EAA8BiC,QAA9B,EAAgD;EAE5C,IAAMC,MAAM,GAAGlC,CAAC,CAAC,MAAD,CAAD,CAAU,MAAV,CAAf;;EAEA,QAAQkC,MAAR;IACI,KAAK,MAAL;MAAe,OAAO,IAAIjE,IAAJ,EAAP;;IACf,KAAK,MAAL;MAAe,OAAO,IAAIA,IAAJ,EAAP;;IACf,KAAK,QAAL;MAAe,OAAO,IAAIT,MAAJ,EAAP;;IACf,KAAK,MAAL;MAAe,OAAO,IAAID,IAAJ,EAAP;;IACf,KAAK,MAAL;MAAe,OAAO,IAAIS,IAAJ,EAAP;;IACf,KAAK,MAAL;MAAe,OAAO,IAAIL,IAAJ,CAAS,CAACsE,QAAQ,IAAI,EAAb,EAAiB,CAAjB,CAAT,CAAP;;IACf,KAAK,QAAL;MAAe,OAAO,IAAInE,MAAJ,CAAWmE,QAAQ,IAAI,EAAvB,CAAP;;IACf,KAAK,SAAL;MAAgB,OAAO,IAAInE,MAAJ,CAAWmE,QAAQ,IAAI,EAAvB,CAAP;EARpB;;EAWA,QAAQC,MAAR;IACI,KAAK,KAAL;MAAY;QACR,IAAMC,CAAC,GAAGnC,CAAC,CAAC,MAAD,CAAX;QACA,OAAO,IAAI9B,GAAJ,CAAQiE,CAAC,CAAC,UAAD,CAAT,EAAuBA,CAAC,CAAC,UAAD,CAAxB,CAAP;MACH;;IACD,KAAK,eAAL;MAAsB;QAClB,IAAMA,EAAC,GAAGnC,CAAC,CAAC,MAAD,CAAX;QACA,OAAO,IAAI7B,KAAJ,CAAUW,SAAS,CAACqD,EAAC,CAAC,WAAD,CAAF,CAAnB,CAAP;MACH;;IACD,KAAK,SAAL;MAAgB;QACZ,IAAMA,GAAC,GAAGnC,CAAC,CAAC,MAAD,CAAX;QACA,OAAO,IAAIvC,OAAJ,CAAY0E,GAAC,CAAC,OAAD,CAAb,EAAwBA,GAAC,CAAC,WAAD,CAAzB,CAAP;MACH;;IACD,KAAK,MAAL;MAAa;QACT,IAAMA,GAAC,GAAGnC,CAAC,CAAC,MAAD,CAAX;QACA,OAAO,IAAI5B,KAAJ,CAAUa,QAAQ,CAACkD,GAAC,CAAC,MAAD,CAAF,CAAlB,CAAP;MACH;;IACD,KAAK,MAAL;MAAa;QACT,IAAMA,GAAC,GAAGnC,CAAC,CAAC,MAAD,CAAX;QACA,OAAO,IAAI3B,IAAJ,CAASQ,QAAQ,CAACsD,GAAC,CAAC,MAAD,CAAF,CAAjB,EAAqCA,GAAC,CAAC,UAAD,CAAtC,CAAP;MACH;;IACD,KAAK,WAAL;MAAkB;QACd,IAAMA,GAAC,GAAGnC,CAAC,CAAC,MAAD,CAAX;QACA,OAAO,IAAIzB,SAAJ,CAAcM,QAAQ,CAACsD,GAAC,CAAC,MAAD,CAAF,CAAtB,EAA0CA,GAAC,CAAC,UAAD,CAA3C,CAAP;MACH;;IACD,KAAK,UAAL;MAAiB;QACb,IAAMA,GAAC,GAAGnC,CAAC,CAAC,MAAD,CAAX;QACA,OAAO,IAAI1B,QAAJ,CAAaS,YAAY,CAACoD,GAAC,CAAC,MAAD,CAAF,CAAzB,CAAP;MACH;;IACD,KAAK,OAAL;MAAc;QACV,IAAMA,GAAC,GAAGnC,CAAC,CAAC,MAAD,CAAX;QACA,OAAO,IAAIjC,KAAJ,CAAUiB,SAAS,CAACmD,GAAC,CAAC,MAAD,CAAF,CAAnB,EAAwCA,GAAC,CAAC,SAAD,CAAD,IAAgB,EAAxD,EAA6DF,QAAQ,IAAI,EAAzE,CAAP;MACH;;IACD,KAAK,iBAAL;MAAwB;QACpB,IAAME,GAAC,GAAGnC,CAAC,CAAC,MAAD,CAAX;QACA,OAAO,IAAItC,eAAJ,CAAoByE,GAAC,CAAC,WAAD,CAArB,CAAP;MACH;;IACD,KAAK,eAAL;MAAsB;QAClB,IAAMA,GAAC,GAAGnC,CAAC,CAAC,MAAD,CAAX;QACA,OAAO,IAAIpC,aAAJ,CAAkBuE,GAAC,CAAC,UAAD,CAAnB,EAAiC,CAACF,QAAQ,IAAI,EAAb,EAAiB,CAAjB,CAAjC,CAAP;MACH;;IACD,KAAK,KAAL;MAAY;QACR,IAAME,IAAC,GAAGnC,CAAC,CAAC,MAAD,CAAX;QACA,OAAO,IAAInC,IAAJ,CAAS,CAACoE,QAAQ,IAAI,EAAb,EAAiB,CAAjB,CAAT,EAA8BE,IAAC,CAAC,YAAD,CAA/B,CAAP;MACH;EA5CL;;EA8CA,MAAM,IAAIC,KAAJ,gCAAiCF,MAAjC,QAAN;AACH","names":["Schema","Field","Dictionary","Utf8","Binary","Decimal","FixedSizeBinary","List","FixedSizeList","Map_","Struct","Union","Bool","Null","Int","Float","Date_","Time","Interval","Timestamp","Int32","DictionaryBatch","RecordBatch","FieldNode","BufferRegion","TimeUnit","Precision","IntervalUnit","UnionMode","DateUnit","schemaFromJSON","_schema","dictionaries","Map","schemaFieldsFromJSON","customMetadataFromJSON","recordBatchFromJSON","b","fieldNodesFromJSON","buffersFromJSON","dictionaryBatchFromJSON","filter","Boolean","map","f","fromJSON","fieldChildrenFromJSON","_field","xs","reduce","fieldNodes","column","nullCountFromJSON","buffers","i","n","length","push","validity","sum","val","fieldFromJSON","id","keys","field","dictMeta","type","dictType","typeFromJSON","has","indexTypeFromJSON","set","get","_metadata","Object","entries","_type","children","typeId","t","Error"],"sources":["ipc/metadata/json.ts"],"sourcesContent":["// Licensed to the Apache Software Foundation (ASF) under one\n// or more contributor license agreements.  See the NOTICE file\n// distributed with this work for additional information\n// regarding copyright ownership.  The ASF licenses this file\n// to you under the Apache License, Version 2.0 (the\n// \"License\"); you may not use this file except in compliance\n// with the License.  You may obtain a copy of the License at\n//\n//   http://www.apache.org/licenses/LICENSE-2.0\n//\n// Unless required by applicable law or agreed to in writing,\n// software distributed under the License is distributed on an\n// \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n// KIND, either express or implied.  See the License for the\n// specific language governing permissions and limitations\n// under the License.\n\nimport { Schema, Field } from '../../schema';\nimport {\n    DataType, Dictionary, TimeBitWidth,\n    Utf8, Binary, Decimal, FixedSizeBinary,\n    List, FixedSizeList, Map_, Struct, Union,\n    Bool, Null, Int, Float, Date_, Time, Interval, Timestamp, IntBitWidth, Int32, TKeys,\n} from '../../type';\n\nimport { DictionaryBatch, RecordBatch, FieldNode, BufferRegion } from './message';\nimport { TimeUnit, Precision, IntervalUnit, UnionMode, DateUnit } from '../../enum';\n\n/** @ignore */\nexport function schemaFromJSON(_schema: any, dictionaries: Map<number, DataType> = new Map()) {\n    return new Schema(\n        schemaFieldsFromJSON(_schema, dictionaries),\n        customMetadataFromJSON(_schema['customMetadata']),\n        dictionaries\n    );\n}\n\n/** @ignore */\nexport function recordBatchFromJSON(b: any) {\n    return new RecordBatch(\n        b['count'],\n        fieldNodesFromJSON(b['columns']),\n        buffersFromJSON(b['columns'])\n    );\n}\n\n/** @ignore */\nexport function dictionaryBatchFromJSON(b: any) {\n    return new DictionaryBatch(\n        recordBatchFromJSON(b['data']),\n        b['id'], b['isDelta']\n    );\n}\n\n/** @ignore */\nfunction schemaFieldsFromJSON(_schema: any, dictionaries?: Map<number, DataType>) {\n    return (_schema['fields'] || []).filter(Boolean).map((f: any) => Field.fromJSON(f, dictionaries));\n}\n\n/** @ignore */\nfunction fieldChildrenFromJSON(_field: any, dictionaries?: Map<number, DataType>): Field[] {\n    return (_field['children'] || []).filter(Boolean).map((f: any) => Field.fromJSON(f, dictionaries));\n}\n\n/** @ignore */\nfunction fieldNodesFromJSON(xs: any[]): FieldNode[] {\n    return (xs || []).reduce<FieldNode[]>((fieldNodes, column: any) => [\n        ...fieldNodes,\n        new FieldNode(\n            column['count'],\n            nullCountFromJSON(column['VALIDITY'])\n        ),\n        ...fieldNodesFromJSON(column['children'])\n    ], [] as FieldNode[]);\n}\n\n/** @ignore */\nfunction buffersFromJSON(xs: any[], buffers: BufferRegion[] = []): BufferRegion[] {\n    for (let i = -1, n = (xs || []).length; ++i < n;) {\n        const column = xs[i];\n        column['VALIDITY'] && buffers.push(new BufferRegion(buffers.length, column['VALIDITY'].length));\n        column['TYPE'] && buffers.push(new BufferRegion(buffers.length, column['TYPE'].length));\n        column['OFFSET'] && buffers.push(new BufferRegion(buffers.length, column['OFFSET'].length));\n        column['DATA'] && buffers.push(new BufferRegion(buffers.length, column['DATA'].length));\n        buffers = buffersFromJSON(column['children'], buffers);\n    }\n    return buffers;\n}\n\n/** @ignore */\nfunction nullCountFromJSON(validity: number[]) {\n    return (validity || []).reduce((sum, val) => sum + +(val === 0), 0);\n}\n\n/** @ignore */\nexport function fieldFromJSON(_field: any, dictionaries?: Map<number, DataType>) {\n\n    let id: number;\n    let keys: TKeys | null;\n    let field: Field | void;\n    let dictMeta: any;\n    let type: DataType<any>;\n    let dictType: Dictionary;\n\n    // If no dictionary encoding\n    if (!dictionaries || !(dictMeta = _field['dictionary'])) {\n        type = typeFromJSON(_field, fieldChildrenFromJSON(_field, dictionaries));\n        field = new Field(_field['name'], type, _field['nullable'], customMetadataFromJSON(_field['customMetadata']));\n    }\n    // tslint:disable\n    // If dictionary encoded and the first time we've seen this dictionary id, decode\n    // the data type and child fields, then wrap in a Dictionary type and insert the\n    // data type into the dictionary types map.\n    else if (!dictionaries.has(id = dictMeta['id'])) {\n        // a dictionary index defaults to signed 32 bit int if unspecified\n        keys = (keys = dictMeta['indexType']) ? indexTypeFromJSON(keys) as TKeys : new Int32();\n        dictionaries.set(id, type = typeFromJSON(_field, fieldChildrenFromJSON(_field, dictionaries)));\n        dictType = new Dictionary(type, keys, id, dictMeta['isOrdered']);\n        field = new Field(_field['name'], dictType, _field['nullable'], customMetadataFromJSON(_field['customMetadata']));\n    }\n    // If dictionary encoded, and have already seen this dictionary Id in the schema, then reuse the\n    // data type and wrap in a new Dictionary type and field.\n    else {\n        // a dictionary index defaults to signed 32 bit int if unspecified\n        keys = (keys = dictMeta['indexType']) ? indexTypeFromJSON(keys) as TKeys : new Int32();\n        dictType = new Dictionary(dictionaries.get(id)!, keys, id, dictMeta['isOrdered']);\n        field = new Field(_field['name'], dictType, _field['nullable'], customMetadataFromJSON(_field['customMetadata']));\n    }\n    return field || null;\n}\n\n/** @ignore */\nfunction customMetadataFromJSON(_metadata?: object) {\n    return new Map<string, string>(Object.entries(_metadata || {}));\n}\n\n/** @ignore */\nfunction indexTypeFromJSON(_type: any) {\n    return new Int(_type['isSigned'], _type['bitWidth']);\n}\n\n/** @ignore */\nfunction typeFromJSON(f: any, children?: Field[]): DataType<any> {\n\n    const typeId = f['type']['name'];\n\n    switch (typeId) {\n        case 'NONE':   return new Null();\n        case 'null':   return new Null();\n        case 'binary': return new Binary();\n        case 'utf8':   return new Utf8();\n        case 'bool':   return new Bool();\n        case 'list':   return new List((children || [])[0]);\n        case 'struct': return new Struct(children || []);\n        case 'struct_': return new Struct(children || []);\n    }\n\n    switch (typeId) {\n        case 'int': {\n            const t = f['type'];\n            return new Int(t['isSigned'], t['bitWidth'] as IntBitWidth);\n        }\n        case 'floatingpoint': {\n            const t = f['type'];\n            return new Float(Precision[t['precision']] as any);\n        }\n        case 'decimal': {\n            const t = f['type'];\n            return new Decimal(t['scale'], t['precision']);\n        }\n        case 'date': {\n            const t = f['type'];\n            return new Date_(DateUnit[t['unit']] as any);\n        }\n        case 'time': {\n            const t = f['type'];\n            return new Time(TimeUnit[t['unit']] as any, t['bitWidth'] as TimeBitWidth);\n        }\n        case 'timestamp': {\n            const t = f['type'];\n            return new Timestamp(TimeUnit[t['unit']] as any, t['timezone']);\n        }\n        case 'interval': {\n            const t = f['type'];\n            return new Interval(IntervalUnit[t['unit']] as any);\n        }\n        case 'union': {\n            const t = f['type'];\n            return new Union(UnionMode[t['mode']] as any, (t['typeIds'] || []), children || []);\n        }\n        case 'fixedsizebinary': {\n            const t = f['type'];\n            return new FixedSizeBinary(t['byteWidth']);\n        }\n        case 'fixedsizelist': {\n            const t = f['type'];\n            return new FixedSizeList(t['listSize'], (children || [])[0]);\n        }\n        case 'map': {\n            const t = f['type'];\n            return new Map_((children || [])[0], t['keysSorted']);\n        }\n    }\n    throw new Error(`Unrecognized type: \"${typeId}\"`);\n}\n"]},"metadata":{},"sourceType":"module"}